<?xml version="1.0" encoding="utf-8"?>
<search> 
  
  
    
    <entry>
      <title>Mysql一致性视图</title>
      <link href="/2019/10/06/mysql-ke-chong-fu-du-ge-chi-ji-bie/"/>
      <url>/2019/10/06/mysql-ke-chong-fu-du-ge-chi-ji-bie/</url>
      
        <content type="html"><![CDATA[<h2 id="Mysql一致性视图"><a href="#Mysql一致性视图" class="headerlink" title="Mysql一致性视图"></a>Mysql一致性视图</h2><h3 id="RC与RR的实现方式：一致性读视图"><a href="#RC与RR的实现方式：一致性读视图" class="headerlink" title="RC与RR的实现方式：一致性读视图"></a>RC与RR的实现方式：一致性读视图</h3><p>InnoDB在实现MVCC时用到<strong>一致性读视图</strong>，<code>consistent read view</code>，用于支持 RC（Read Committed，读提交）和 RR（Repeatable Read，可重复读）隔离级别的实现。它没有物理结构，作用是事务执行期间用来定义“我能看到什么数据”。</p><h3 id="快照在MVCC里是如何工作的？"><a href="#快照在MVCC里是如何工作的？" class="headerlink" title="快照在MVCC里是如何工作的？"></a>快照在MVCC里是如何工作的？</h3><p><strong>可重复读隔离级别下，事务在启动时拍了基于整库的快照。</strong><br>InnoDB 里面每个事务有一个唯一的事务 ID，叫作 transaction id。它是在事务开始的时候向 InnoDB 的事务系统申请的，是按申请顺序严格递增的。每行数据也都是有多个版本的。每次事务更新数据的时候，都会生成一个新的数据版本，并且把 transaction id 赋值给这个数据版本的事务 ID，记为 row trx_id。同时，旧的数据版本要保留，并且在新的数据版本中，能够有信息可以直接拿到它。（通过执行更新操作时生成的undo log回滚日志）</p><p>InnoDB 利用了“所有数据都有多个版本”的这个特性，实现了“秒级创建快照”的能力。</p><blockquote><p>可重复读的定义，一个事务启动的时候，能够看到所有已经提交的事务结果。但是之后，这个事务执行期间，其他事务的更新对它不可见。</p></blockquote><h3 id="事务的视图数组与数据版本row-trx-id"><a href="#事务的视图数组与数据版本row-trx-id" class="headerlink" title="事务的视图数组与数据版本row trx_id"></a>事务的视图数组与数据版本row trx_id</h3><p>在实现上， <strong>InnoDB 为每个事务构造了一个数组</strong>，用来保存这个<strong>事务启动瞬间</strong>，当前正在“活跃”的所有事务 ID。<br><strong>“活跃”指的就是，启动了但还没提交。</strong></p><blockquote><p>低水位：数组里面事务 ID 的最小值记。<br>高水位：当前系统里面已经创建过的事务 ID 的最大值加 1 。<br>视图数组和高水位，就组成了当前事务的一致性视图（read-view）。</p></blockquote><p><img src="https://icecrea-1255483371.cos.ap-beijing.myqcloud.com/Mysql/%E4%BA%8B%E5%8A%A1%E6%95%B0%E7%BB%84.png" alt><br>一个数据版本的 row trx_id，有以下可能：</p><pre><code>1. 在绿色部分，表示这个版本是已提交的事务或者是当前事务自己生成的，这个数据是可见的；2. 如果落在红色部分，表示这个版本是由将来启动的事务生成的，是肯定不可见的；3. 如果落在黄色部分，那就包括两种情况    a. 若 row trx_id 在数组中，表示这个版本是由还没提交的事务生成的，不可见；    b. 若 row trx_id 不在数组中，表示这个版本是已经提交了的事务生成的，可见。</code></pre><h3 id="实战分析"><a href="#实战分析" class="headerlink" title="实战分析"></a>实战分析</h3><pre><code>mysql&gt; CREATE TABLE `t` (  `id` int(11) NOT NULL,  `k` int(11) DEFAULT NULL,  PRIMARY KEY (`id`)) ENGINE=InnoDB;insert into t(id, k) values(1,1),(2,2);</code></pre><p><img src="https://icecrea-1255483371.cos.ap-beijing.myqcloud.com/Mysql/MVCC.png" alt><br>图中事务B查询结果为3，事务A查询结果为1。下面解释原因：</p><p>可以先做如下假设</p><pre><code>1. 事务 A 开始前，系统里面只有一个活跃事务 ID 是 99；2. 事务 A、B、C 的版本号分别是 100、101、102，且当前系统里只有这四个事务；3. 三个事务开始前，(1,1）这一行数据的 row trx_id 是 90。</code></pre><p>事务A的数组为[99,100]，事务B数组为[99,100,101]，事务C数组为[99,100,101,102]</p><p>事务 C先把数据从 (1,1) 改成了 (1,2)。这时候，这个数据的最新版本的 row trx_id 是 102，而 90 这个版本已经成为了历史版本。第二个有效更新是事务 B，把数据从 (1,2) 改成了 (1,3)。这时候，这个数据的最新版本（即 row trx_id）是 101，而 102 又成为了历史版本。row trx_id更新过程即为90-》102-》101。</p><pre><code>事务A读数据，A的视图数组是 [99,100]，1. 找到当前数据（1，3），row trx_id=101，比高水位大，处于红色区域，不可见；（版本未提交）2. 找到上一个历史版本，一看 row trx_id=102，比高水位大，处于红色区域，不可见；（版本视图创建后提交）3. 找到上一个历史版本（1,1)，它的 row trx_id=90，比低水位小，处于绿色区域，可见。</code></pre><p>更容易理解的分析方法：</p><pre><code>一个数据版本，对于一个事务视图来说，除了自己的更新总是可见以外，有三种情况：1. 版本未提交，不可见；2. 版本已提交，但是是在视图创建后提交的，不可见；3. 版本已提交，而且是在视图创建前提交的，可见。</code></pre><h3 id="更新逻辑：当前读"><a href="#更新逻辑：当前读" class="headerlink" title="更新逻辑：当前读"></a>更新逻辑：当前读</h3><p>结论：<strong>更新数据都是先读后写的，而这个读，只能读当前的值，称为“当前读”（current read）。</strong></p><p>对事务B来说，更新的时候，当前读拿到的数据是 (1,2)，更新后生成了新版本的数据 (1,3)，这个新版本的 row trx_id 是 101。在执行事务 B 查询语句的时候，一看自己的版本号是 101，最新数据的版本号也是 101，是自己的更新，可以直接使用，所以查询得到的 k 的值是 3。</p><p>除了 update 语句外，select 语句如果加锁，也是当前读。<br>所以如果把事务 A 的查询语句 <code>select * from t where id=1</code>修改一下，加上 <code>lock in share mode</code> 或 <code>for update</code>，也都可以读到版本号是 101 的数据，返回的 k 的值是 3。下面这两个 select 语句，就是分别加了读锁（S 锁，共享锁）和写锁（X 锁，排他锁）。</p><pre><code>mysql&gt; select k from t where id=1 lock in share mode;mysql&gt; select k from t where id=1 for update;</code></pre><p>Q：事务的可重复读的能力是怎么实现的？<br>可重复读的核心就是一致性读（consistent read）；而事务更新数据的时候，只能用当前读。如果当前的记录的行锁被其他事务占用的话，就需要进入锁等待。</p><h3 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h3><p>InnoDB 的行数据有多个版本，每个数据版本有自己的 row trx_id，每个事务或者语句有自己的一致性视图。普通查询语句是一致性读，一致性读会根据 row trx_id 和一致性视图确定数据版本的可见性。<br>对于可重复读，查询只承认在事务启动前就已经提交完成的数据；<br>对于读提交，查询只承认在语句启动前就已经提交完成的数据；</p>]]></content>
      
      
      <categories>
          
          <category> MYSQL </category>
          
      </categories>
      
      
        <tags>
            
            <tag> MYSQL </tag>
            
            <tag> MYSQL事务 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Mysql索引</title>
      <link href="/2019/10/06/mysql-suo-yin/"/>
      <url>/2019/10/06/mysql-suo-yin/</url>
      
        <content type="html"><![CDATA[<h2 id="Mysql索引"><a href="#Mysql索引" class="headerlink" title="Mysql索引"></a>Mysql索引</h2><h3 id="索引模型"><a href="#索引模型" class="headerlink" title="索引模型"></a>索引模型</h3><ol><li>哈希表<br> 适用于只有等值查询的场景。不支持最左匹配规则，没办法利用索引完成排序，无法进行范围查询。如果有大量重复键值得情况下，存在哈希碰撞问题</li><li>有序数组<br>有序数组索引只适用于静态存储引擎。查询效率高，但更新数据成本高。</li><li>搜索树<br>二叉树是搜索效率最高的，但是实际上大多数的数据库存储却并不使用二叉树。其原因是，索引不止存在内存中，还要写到磁盘上。<blockquote><p>一棵 100 万节点的平衡二叉树，树高 20。一次查询可能需要访问 20 个数据块。在机械硬盘时代，从磁盘随机读一个数据块需要 10 ms 左右的寻址时间。也就是说，对于一个 100 万行的表，如果使用二叉树来存储，单独访问一个行可能需要 20 个 10 ms 的时间</p></blockquote></li></ol><p>为了让一个查询尽量少地读磁盘，就必须让查询过程访问尽量少的数据块。使用“N 叉”树。这里，“N 叉”树中的“N”取决于数据块的大小。</p><blockquote><p>以 InnoDB 的一个整数字段索引为例，这个 N 差不多是 1200。这棵树高是 4 的时候，就可以存 1200 的 3 次方个值，这已经 17 亿了。考虑到树根的数据块总是在内存中的，一个 10 亿行的表上一个整数字段的索引，查找一个值最多只需要访问 3 次磁盘。其实，树的第二层也有很大概率在内存中，那么访问磁盘的平均次数就更少了。</p></blockquote><h3 id="InnoDB-的索引模型"><a href="#InnoDB-的索引模型" class="headerlink" title="InnoDB 的索引模型"></a>InnoDB 的索引模型</h3><p>在 InnoDB 中，表都是根据主键顺序以索引的形式存放的，这种存储方式的表称为索引组织表。又因为前面我们提到的，InnoDB 使用了 B+ 树索引模型，所以数据都是存储在 B+ 树中的。<br>每一个索引在 InnoDB 里面对应一棵 B+ 树。</p><p>根据叶子节点的内容，索引类型分为主键索引和非主键索引。</p><ul><li>主键索引的叶子节点存的是整行数据，也被称为聚簇索引。</li><li>非主键索引的叶子节点内容是主键的值，非主键索引也被称为二级索引。 </li></ul><p>基于非主键索引的查询需要多扫描一棵索引树。</p><h3 id="索引维护"><a href="#索引维护" class="headerlink" title="索引维护"></a>索引维护</h3><p>B+ 树为了维护索引有序性，在插入新值的时候做必要的维护。如果是递增插入只需要在最大记录后面插入新记录。其它情况，需要逻辑上移动后面数据。如果插入位置所在数据页满了，会申请新数据页挪动部分数据过去，称为<strong>页分裂</strong>，影响性能和数据页的利用率。</p><p>为什么普遍要求建表语句里一定要有自增主键？<code>NOT NULL PRIMARY KEY AUTO_INCREMENT</code></p><ol><li>性能角度<br>自增主键的插入数据模式，符合递增插入的场景。每次插入一条新记录，都是追加操作，都不涉及到挪动其他记录，也不会触发叶子节点的分裂。而有业务逻辑的字段做主键，则往往不容易保证有序插入，这样写数据成本相对较高</li><li>存储空间角度<br>假设你的表中确实有一个唯一字段，比如字符串类型的身份证号。由于每个非主键索引的叶子节点上都是主键的值。如果用身份证号做主键，那么每个二级索引的叶子节点占用约 20 个字节，而如果用整型做主键，则只要 4 个字节，如果是长整型（bigint）则是 8 个字节。</li></ol><p><strong>显然，主键长度越小，普通索引的叶子节点就越小，普通索引占用的空间也就越小。</strong></p><h3 id="覆盖索引"><a href="#覆盖索引" class="headerlink" title="覆盖索引"></a>覆盖索引</h3><p>如果执行的语句是 <code>select ID from T where k between 3 and 5</code>，这时只需要查 ID 的值，而 ID 的值已经在 k 索引树上了，因此可以直接提供查询结果，不需要回表。也就是说，在这个查询里面，索引 k 已经“覆盖了”我们的查询需求，我们称为覆盖索引。</p><h3 id="最左前缀原则"><a href="#最左前缀原则" class="headerlink" title="最左前缀原则"></a>最左前缀原则</h3><p><strong>B+ 树这种索引结构，可以利用索引的“最左前缀”，来定位记录。</strong><br>用（name，age）这个联合索引来分析：SQL 语句的条件是<code>where name like ‘张 %’</code>，也能够用上这个索引。<br>只要满足最左前缀，就可以利用索引来加速检索。这个最左前缀可以是联合索引的最左 N 个字段，也可以是字符串索引的最左 M 个字符。</p><h3 id="索引下推"><a href="#索引下推" class="headerlink" title="索引下推"></a>索引下推</h3><p>以市民表的联合索引（name, age）为例。检索出表中“名字第一个字是张，而且年龄是 10 岁的所有男孩”<br><code>select * from tuser where name like &#39;张 %&#39; and age=10 and ismale=1;</code><br>前缀索引规则，语句在搜索索引树的时候，只能用 “张”，找到第一个满足条件的记录 ID3。之后呢？则比较剩余字段。</p><p>在 MySQL 5.6 之前，只能从 ID3 开始一个个回表。到主键索引上找出数据行，再对比字段值。<br>而 MySQL 5.6 引入的索引下推优化（index condition pushdown)， 可以在索引遍历过程中，对索引中包含的字段先做判断，直接过滤掉不满足条件的记录，减少回表次数。</p><p><img src="https://icecrea-1255483371.cos.ap-beijing.myqcloud.com/Mysql/%E6%97%A0%E7%B4%A2%E5%BC%95%E4%B8%8B%E6%8E%A8.png" alt="无索引下推"><br>无索引下推：在 (name,age) 索引里面我特意去掉了 age 的值，这个过程 InnoDB 并不会去看 age 的值，只是按顺序把“name 第一个字是’张’”的记录一条条取出来回表。因此，需要回表 4 次。</p><p><img src="https://icecrea-1255483371.cos.ap-beijing.myqcloud.com/Mysql/%E7%B4%A2%E5%BC%95%E4%B8%8B%E6%8E%A8.png" alt="索引下推"><br>索引下推：InnoDB 在 (name,age) 索引内部就判断了 age 是否等于 10，对于不等于 10 的记录，直接判断并跳过。在我们的这个例子中，只需要对 ID4、ID5 这两条记录回表取数据判断，就只需要回表 2 次。</p><hr><p>Q：下列重建索引K与主键索引方式是否正确：</p><pre><code>alter table T drop index k;alter table T add index(k);alter table T drop primary key;alter table T add primary key(id);</code></pre><p>A：重建索引 k 的做法是合理的，可以达到省空间的目的。但是，重建主键的过程不合理。不论是删除主键还是创建主键，都会将整个表重建。所以连着执行这两个语句的话，第一个语句就白做了。这两个语句，你可以用这个语句代替 ： alter table T engine=InnoDB。</p><p>参考：<br>丁奇：Mysql实战45讲<br><a href="https://zhuanlan.zhihu.com/p/78982303" target="_blank" rel="noopener">我以为我对Mysql索引很了解，直到我遇到了阿里的面试官</a></p>]]></content>
      
      
      <categories>
          
          <category> MYSQL </category>
          
      </categories>
      
      
        <tags>
            
            <tag> MYSQL </tag>
            
            <tag> 索引 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Mysql锁</title>
      <link href="/2019/10/03/mysql-suo/"/>
      <url>/2019/10/03/mysql-suo/</url>
      
        <content type="html"><![CDATA[<h2 id="Mysql锁"><a href="#Mysql锁" class="headerlink" title="Mysql锁"></a>Mysql锁</h2><p>MySQL 里面的锁大致可以分成全局锁、表级锁和行锁三类</p><h3 id="全局锁"><a href="#全局锁" class="headerlink" title="全局锁"></a>全局锁</h3><p>顾名思义，全局锁就是对整个数据库实例加锁。MySQL 提供了一个加全局读锁的方法，命令是 <code>Flush tables with read lock (FTWRL)</code>。当你需要让整个库处于只读状态的时候，可以使用这个命令，之后其他线程的以下语句会被阻塞：数据更新语句（数据的增删改）、数据定义语句（包括建表、修改表结构等）和更新类事务的提交语句。</p><p><strong>全局锁的典型使用场景是，做全库逻辑备份。</strong>也就是把整库每个表都 select 出来存成文本。<br>主库上备份，那么在备份期间都不能执行更新。从库上备份，那么备份期间从库不能执行主库同步过来的 binlog，会导致主从延迟。</p><p>备份是否可以不加锁？<br>假设备份期间，有一个用户，他购买了一门课程，业务逻辑里就要扣掉他的余额，然后往已购课程里面加上一门课。<br>假设不加锁。如果时间顺序上是先备份账户余额表，然后用户购买，然后备份用户课程表。在备份结果里用户状态为余额没扣，多了一门课程。后续用该备份恢复数据会有问题。<br><strong>不加锁的话，备份系统备份的得到的库不是一个逻辑时间点，这个视图是逻辑不一致的。</strong></p><p>可重复读隔离级别下可以拿到一致性视图。<br>官方自带的逻辑备份工具是 mysqldump。当 mysqldump 使用参数<code>–single-transaction</code>的时候，导数据之前就会启动一个事务，来确保拿到一致性视图。而由于 MVCC 的支持，这个过程中数据是可以正常更新的。<strong>single-transaction 方法只适用于所有的表使用事务引擎的库。</strong></p><h3 id="表级锁"><a href="#表级锁" class="headerlink" title="表级锁"></a>表级锁</h3><p>MySQL 里面表级别的锁有两种：一种是表锁，一种是元数据锁（meta data lock，MDL)。</p><h4 id="表锁"><a href="#表锁" class="headerlink" title="表锁"></a>表锁</h4><p>表锁的语法是 <code>lock tables … read/write</code>。与 FTWRL 类似，可以用 <code>unlock tables</code> 主动释放锁，也可以在客户端断开的时候自动释放。需要注意，<code>lock tables</code> 语法除了会限制别的线程的读写外，也限定了本线程接下来的操作对象。 </p><p><strong>如果在某个线程 A 中执行 lock tables t1 read, t2 write; 这个语句，则其他线程写 t1、读写 t2 的语句都会被阻塞。同时，线程 A 在执行 unlock tables 之前，也只能执行读 t1、读写 t2 的操作。连写 t1 都不允许，自然也不能访问其他表</strong></p><p>线程A对T加读锁，限制其它线程写T，限制本线程写T，线程A不能访问其它表。<br>线程A对T加写锁，限制其它线程读写T，线程A不能访问其它表。</p><h4 id="MDL锁"><a href="#MDL锁" class="headerlink" title="MDL锁"></a>MDL锁</h4><p>另一类表级的锁是 MDL（metadata lock)。<br>MDL 不需要显式使用，在访问一个表的时候会被自动加上。<br>在 MySQL 5.5 版本中引入了 MDL，<strong>当对一个表做增删改查操作的时候，加 MDL 读锁；当要对表做结构变更操作的时候，加 MDL 写锁。</strong></p><ul><li>读锁之间不互斥，因此你可以有多个线程同时对一张表增删改查。</li><li>读写锁之间、写锁之间是互斥的，用来保证变更表结构操作的安全性。</li></ul><p><strong>踩坑：给一个小表加个字段，导致整个库挂了。</strong><br><img src="https://icecrea-1255483371.cos.ap-beijing.myqcloud.com/Mysql/MDL.jpg" alt></p><p>如图：sessionA先启动，加MDL读锁，B也是加MDL读锁，不影响B查询。C需要MDL写锁，因为A的MDL读锁还没有释放，所以C会被阻塞。但是之后在表t上申请MDL读锁的请求也会被C阻塞（增删改查）。等于表现在不可读写了。(问题：C没有加锁成功为什么会阻塞D？应该是因为CD均在同一个锁队列中，决定谁先执行，sessionC在等待的时候就开始阻塞后来的请求了)</p><p>如果表查询语句频繁且客户端有重试，即超时起一个新session请求，库的线程很快会饱满。<br><strong>事务中的MDL锁，在语句执行开始时申请，事务提交后再释放。</strong></p><p><strong>Q：如何安全地给小表加字段？</strong><br>1.首先我们要解决长事务，事务不提交，就会一直占着 MDL 锁。在 MySQL 的 information_schema 库的 innodb_trx 表中，你可以查到当前执行中的事务。如果你要做 DDL 变更的表刚好有长事务在执行，要考虑先暂停 DDL，或者 kill 掉这个长事务。<br>2.如果是一个热点表，请求频繁kill不过来。理想的机制是，在 alter table 语句里面设定等待时间，如果在这个指定的等待时间里面能够拿到 MDL 写锁最好，拿不到也不要阻塞后面的业务语句，先放弃。MariaDB 已经合并了 AliSQL 的这个功能，所以这两个开源分支目前都支持 DDL NOWAIT/WAIT n 这个语法。<br><code>ALTER TABLE tbl_name NOWAIT add column ...</code>  <code>ALTER TABLE tbl_name WAIT N add column ...</code></p><h3 id="行锁"><a href="#行锁" class="headerlink" title="行锁"></a>行锁</h3><p>MySQL 的行锁是在引擎层由各个引擎自己实现的。MyISAM 引擎不支持行锁。</p><p><strong>在 InnoDB 事务中，行锁是在需要的时候才加上的，但并不是不需要了就立刻释放，而是要等到事务结束时才释放。这个就是两阶段锁协议。</strong></p><p><strong>如果你的事务中需要锁多个行，要把最可能造成锁冲突、最可能影响并发度的锁尽量往后放。</strong><br>如影院购票，假设有用户余额扣除票价，影院账户余额增加票价，记录日志操作。在事务中，我们就可以把容易冲突的影院账户余额增加票价安排到最后，这样影院账户余额这一行锁时间就最小，最大程度减少了事务的锁等待，提升并发度。</p><h4 id="死锁和死锁检测"><a href="#死锁和死锁检测" class="headerlink" title="死锁和死锁检测"></a>死锁和死锁检测</h4><p><img src="https://icecrea-1255483371.cos.ap-beijing.myqcloud.com/Mysql/sisuo.jpg" alt><br>如图，事务 A 和事务 B 在互相等待对方的资源释放，就是进入了死锁状态。出现死锁后有两种策略：</p><ol><li>直接进入等待，直到超时。这个超时时间可以通过参数 innodb_lock_wait_timeout 来设置。<br>在 InnoDB 中，innodb_lock_wait_timeout 的默认值是 50s。当出现死锁以后，第一个被锁住的线程要过 50s 才会超时退出。设置太小又可能导致误判，简单的锁等待。</li><li>发起死锁检测，发现死锁后，主动回滚死锁链条中的某一个事务，让其他事务得以继续执行。将参数 innodb_deadlock_detect 设置为 on，表示开启这个逻辑。默认开启。<br>每当一个事务被锁的时候，就要看看它所依赖的线程有没有被别人锁住，如此循环，最后判断是否出现了循环等待，也就是死锁。</li></ol><p>每个新来的被堵住的线程，都要判断会不会由于自己的加入导致了死锁，这是一个时间复杂度是 O(n) 的操作。假设有 1000 个并发线程要同时更新同一行，那么死锁检测操作就是 100 万这个量级的。虽然最终检测的结果是没有死锁，但是这期间要消耗大量的 CPU 资源。因此，你就会看到 CPU 利用率很高，但是每秒却执行不了几个事务。</p><p>怎么解决由这种热点行更新导致的性能问题呢？<br>1.控制并发度。如同一行同时最多只有 10 个线程在更新，那么死锁检测的成本很低。并发控制要放在服务端。<br>2.通过将一行改成逻辑上的多行来减少锁冲突。还是以影院账户为例，可以考虑放在多条记录上，比如 10 个记录，影院的账户总额等于这 10 个记录的值的总和。这样每次要给影院账户加金额的时候，随机选其中一条记录来加。这样每次冲突概率变成原来的 1/10，可以减少锁等待个数，也就减少了死锁检测的 CPU 消耗。</p><p><strong>Q：如果你要删除一个表里面的前 10000 行数据，有以下三种方法可以做到，选择哪一种？</strong><br>第一种，直接执行 delete from T limit 10000;<br>第二种，在一个连接中循环执行 20 次 delete from T limit 500;<br>第三种，在 20 个连接中同时执行 delete from T limit 500。</p><p>A：第二种比较合适。第一种方式单个语句占用时间长，锁时间长，且大事务会导致主从延迟。第三种会人为造成锁冲突。</p><p>参考：<br>丁奇：Mysql实战45讲</p>]]></content>
      
      
      <categories>
          
          <category> MYSQL </category>
          
      </categories>
      
      
        <tags>
            
            <tag> MYSQL </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>索引失效实战篇 - 函数操作</title>
      <link href="/2019/10/03/suo-yin-shi-xiao-shi-zhan-pian-han-shu-cao-zuo/"/>
      <url>/2019/10/03/suo-yin-shi-xiao-shi-zhan-pian-han-shu-cao-zuo/</url>
      
        <content type="html"><![CDATA[<h2 id="索引失效实战篇-函数操作"><a href="#索引失效实战篇-函数操作" class="headerlink" title="索引失效实战篇 - 函数操作"></a>索引失效实战篇 - 函数操作</h2><h3 id="1、-条件字段函数操作"><a href="#1、-条件字段函数操作" class="headerlink" title="1、 条件字段函数操作"></a>1、 条件字段函数操作</h3><p><code>mysql&gt; select count(*) from tradelog where month(t_modified)=7;</code></p><p>B+ 树提供的这个快速定位能力，来源于同一层兄弟节点的有序性。<strong>对索引字段做函数操作，可能会破坏索引值的有序性，因此优化器就决定放弃走树搜索功能</strong>。注意：优化器并不是要放弃使用这个索引。对比索引大小选择更小的索引。加了 month() 函数操作，MySQL 无法再使用索引快速定位功能，而只能使用全索引扫描。</p><p>优化器在个问题上确实有“偷懒”行为，即使是对于不改变有序性的函数，也不会考虑使用索引。比如，对于 <code>select * from tradelog where id + 1 = 10000</code></p><h3 id="2、-隐式类型转换"><a href="#2、-隐式类型转换" class="headerlink" title="2、 隐式类型转换"></a>2、 隐式类型转换</h3><p><code>select * from tradelog where tradeid=110717;</code><br>tradeid 的字段类型是 varchar(32)，而输入的参数却是整型，所以需要做类型转换。</p><p>数据类型转换的规则是什么？有一个简单的方法，看 select “10” &gt; 9 的结果</p><pre><code>1. 如果规则是“将字符串转成数字”，那么就是做数字比较，结果应该是 12. 如果规则是“将数字转成字符串”，那么就是做字符串比较，结果应该是 </code></pre><p>验证结果为1，所以在MYSQL中是将<strong>字符串转换成数字</strong><br>对于优化器来说，上面操作等于<code>select * from tradelog where CAST(tradid AS signed int) = 110717;</code>符合上面规则，<strong>对索引字段做函数操作，优化器会放弃走树搜索功能</strong></p><p>注意：<code>select * from tradelog where id=&quot;83126&quot;;</code>该case中，id是int类型，不会导致全表扫描。因为是字符串转整数，所以会先将入参83126转化成数字，在进入索引搜索。</p><h3 id="3、隐式字符编码转换"><a href="#3、隐式字符编码转换" class="headerlink" title="3、隐式字符编码转换"></a>3、隐式字符编码转换</h3><p><code>select d.* from tradelog l, trade_detail d where d.tradeid=l.tradeid and l.id=2;</code><br>链表查询交易记录标和详情表，通过tradeid关联，tradedetail是utf8编码，tradelog是utf8mb4。<br>查询分析结果如下：<br><img src="https://icecrea-1255483371.cos.ap-beijing.myqcloud.com/Mysql/lianbiaochaxun.png" alt></p><pre><code>1. 第一行显示优化器会先在交易记录表 tradelog 上查到 id=2 的行，这个步骤用上了主键索引，rows=1 表示只扫描一行2. 第二行 key=NULL，表示没有用上交易详情表 trade_detail 上的 tradeid 索引，进行了全表扫描</code></pre><p>表 trade_detail 里 tradeid 字段上是有索引的，为什么没有使用？因为这两个表的字符集不同，一个是 utf8，一个是 utf8mb4，所以做表连接查询的时候用不上关联字段的索引。那为什么字符集不同就用不上索引呢？</p><blockquote><p>字符集 utf8mb4 是 utf8 的超集，所以当这两个类型的字符串在做比较的时候，MySQL 内部的操作是，先把 utf8 字符串转成 utf8mb4 字符集，再做比较。可以理解为=“按数据长度增加的方向”进行转换。</p></blockquote><p>实际上等同如下写法：<br><code>select * from trade_detail where CONVERT(traideid USING utf8mb4)=$L2.tradeid.value</code></p><p><strong>连接过程中要求在被驱动表的索引字段上加函数操作</strong>，是直接导致对被驱动表做全表扫描的原因。</p><p>对比验证<code>select l.operator from tradelog l , trade_detail d where d.tradeid=l.tradeid and d.id=4;</code><br>此时转换成<code>select operator from tradelog where traideid =CONVERT($R4.tradeid.value USING utf8mb4);</code>CONVERT 函数是加在输入参数上的，这样就可以用上被驱动表的 traideid 索引。</p><p>第一种查询的解决方案：</p><ol><li>转换成utf8mb4</li><li>修改SQL语句 <code>select d.* from tradelog l , trade_detail d where d.tradeid=CONVERT(l.tradeid USING utf8) and l.id=2;</code></li></ol><h3 id="总结："><a href="#总结：" class="headerlink" title="总结："></a>总结：</h3><p><strong>对索引字段做函数操作，可能会破坏索引值的有序性，因此优化器就决定放弃走树搜索功能。</strong></p><p>参考：<br>丁奇：MYSQL实战45讲</p>]]></content>
      
      
      <categories>
          
          <category> MYSQL </category>
          
      </categories>
      
      
        <tags>
            
            <tag> MYSQL </tag>
            
            <tag> 索引 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>JVM问题排查指令总结</title>
      <link href="/2019/09/29/jvm-wen-ti-pai-cha-zhi-ling-zong-jie/"/>
      <url>/2019/09/29/jvm-wen-ti-pai-cha-zhi-ling-zong-jie/</url>
      
        <content type="html"><![CDATA[<h2 id="JVM问题排查指令总结"><a href="#JVM问题排查指令总结" class="headerlink" title="JVM问题排查指令总结"></a>JVM问题排查指令总结</h2><h4 id="常用分析指令"><a href="#常用分析指令" class="headerlink" title="常用分析指令"></a>常用分析指令</h4><ol><li><p>查看各个类的实例大小与个数<br><code>sudo -u tomcat jmap -histo pid</code></p></li><li><p>DUMP内存，获取对应的内存快照<br><code>sudo -u tomcat jmap -dump:format=b,file=dumpxx.bin pid</code> </p></li><li><p>CPU飙高排查线程信息<br><code>top -Hp pid</code> 查看Java进程信息 p : 根据CPU使用百分比大小进行排序<br><code>printf &quot;%x\n&quot; 21742</code> 将CPU高的线程ID转换成十六进制<br><code>sudo -u tomcat jstack -l 21711 | grep 54ee</code> 查看线程栈中对应CPU高的线程信息</p></li><li><p>统计进程状态个数<br><code>sudo -utomcat jstack 5020 |grep &#39;java.lang.Thread.State&#39; | awk &#39;{print $2,$3,$4,$5}&#39; | sort | uniq -c</code></p><pre><code>36 RUNNABLE3 TIMED_WAITING (on object monitor)13 TIMED_WAITING (parking)6 TIMED_WAITING (sleeping)3 WAITING (on object monitor)47 WAITING (parking)</code></pre></li></ol><hr><h4 id="MAT-使用简介"><a href="#MAT-使用简介" class="headerlink" title="MAT 使用简介"></a>MAT 使用简介</h4><p>Shallow Heap ：一个对象内存的消耗大小，不包含对其他对象的引用；<br>Retained Heap ：是shallow Heap的总和，也就是该对象被GC之后所能回收的内存大小<br>在某一项上右键打开菜单选择 list objects ：<br>with incoming references 将列出哪些类引入该类；<br>with outgoing references 列出该类引用了哪些类</p>]]></content>
      
      
      <categories>
          
          <category> JVM </category>
          
      </categories>
      
      
        <tags>
            
            <tag> JVM </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>CLOSE-WAIT的排查之旅</title>
      <link href="/2019/09/29/close-wait-de-pai-cha-zhi-lu/"/>
      <url>/2019/09/29/close-wait-de-pai-cha-zhi-lu/</url>
      
        <content type="html"><![CDATA[<h2 id="CLOSE-WAIT的排查之旅"><a href="#CLOSE-WAIT的排查之旅" class="headerlink" title="CLOSE-WAIT的排查之旅"></a>CLOSE-WAIT的排查之旅</h2><h4 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h4><p>通过监控中发现，线上机器TCP连接中，CLOSE-WAIT状态的量较高。对该问题进行排查</p><h4 id="TCP基础介绍"><a href="#TCP基础介绍" class="headerlink" title="TCP基础介绍"></a>TCP基础介绍</h4><p>首先介绍下TCP连接的状态，四次挥手关闭连接的状态变化如下图所示。<br>从图中可以看到，<strong>主动关闭</strong>的一方会发出FIN包，被动关闭的一方响应ACK包，此时被动关闭的一方进入CLOSE-WAIT状态。如果一切正常，被动关闭的一方也会发出FIN包，进入LAST-ACK状态。<br><img src="https://icecrea-1255483371.cos.ap-beijing.myqcloud.com/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/tcp_close_geek.jpg" alt></p><p>通常情况下，服务器中CLOSE-WAIT状态停留时间很短，<strong>如果发现大量CLOSE-WAIT状态，说明被动关闭的一方没有及时发出FIN包</strong></p><p>可能导致问题的原因：</p><ul><li>程序未正确释放资源</li><li>客户端超时，主动关闭连接，同时服务器却没有正确释放连接</li></ul><blockquote><p>举例一个场景：<br>服务器A会去请求服务器B上面的apache获取文件资源，正常情况下，如果请求成功，那么在抓取完资源后服务器A会主动发出关闭连接的请求，这个时候就是主动关闭连接，连接状态我们可以看到是TIME_WAIT。如果一旦发生异常呢？假设请求的资源服务器B上并不存在，那么这个时候就会由服务器B发出关闭连接的请求，服务器A就是被动的关闭了连接，如果服务器A被动关闭连接之后自己并没有释放连接，那就会造成CLOSE_WAIT的状态了。</p></blockquote><p>而对于JAVA项目来说，则需要重点观察HTTP相关调用与连接的释放。</p><h4 id="代码层面白盒分析"><a href="#代码层面白盒分析" class="headerlink" title="代码层面白盒分析"></a>代码层面白盒分析</h4><p>一开始是从代码层面进行分析，我们使用了Http-Client连接池，<br>对于3.1的版本，我们使用了<code>MultiThreadedHttpConnectionManager</code>作为多线程管理器，并且在<code>finally</code>块中，调用了<code>HttpMethod#releaseConnection</code>方法，对连接进行释放，并没有发现问题。</p><p>而因为使用了连接池复用的缘故，同样不建议采用手动关闭连接的形式。如</p><ol><li>通过设置header由服务端自动关闭。<code>method.setHeader(&quot;Connection&quot;, &quot;close&quot;)</code><br>HTTP1.1中默认启用Keep-Alive，这是HTTP一种连接复用机制，加入”Connection: close”会关闭长连接，无法在一个TCP连接进行多次HTTP会话，降低性能。</li><li>在<code>method.releaseConnection()</code> 之后 通过获取HttpConnectionManager，进行关闭<code>hc.getConnectionManager().shutdown();</code>  直接关闭连接池，同样对性能影响较大不可取。</li></ol><h4 id="抓包分析定位请求"><a href="#抓包分析定位请求" class="headerlink" title="抓包分析定位请求"></a>抓包分析定位请求</h4><p>在代码中我们发现使用了HttpClient进行网络请求，但是用法与调用比较混乱，3.x，4.x，以及公司封装版本均有使用，仅仅白盒分析难以发现问题。所以通过tcpdump对线上机器进行抓包分析。</p><ol><li>dump所有tcp报文到文件<br><code>sudo tcpdump  -nn -w flightorder.pcap -v</code></li><li>查看监控，在closewait的上升期，查询最新的连接信息<br><code>sudo netstat -anp |grep CL</code></li><li>通过最新的close-wait 端口 查看tcp的信息<br><code>tcpdump -r flightorder.pcap |grep &#39;35493&#39;</code></li></ol><p>通过报文中的http请求，锁定应用级别相关api</p><h4 id="一行代码的低级错误"><a href="#一行代码的低级错误" class="headerlink" title="一行代码的低级错误"></a>一行代码的低级错误</h4><p>定位代码发现，在该处调用中，封装了post相关请求，但是在该方法中，每次调用均重新生成了新的HttpClient，而不是公共静态的httpclient。意味着每一次请求均会生成一个新的连接池进行处理。将实例化代码抽出后发布，发现CLOSE-WAIT量消失，问题解决。</p><h4 id="Http的Keep-alive机制"><a href="#Http的Keep-alive机制" class="headerlink" title="Http的Keep-alive机制"></a>Http的Keep-alive机制</h4><p>定位解决了问题，但是还有一些疑问，<strong>主动方是如何触发的关闭呢？</strong></p><p>这里就需要先普及下Http keepalive机制。Http的Keep alive是一种TCP连接复用机制，在同一个TCP连接上传送多个HTTP，提高Socket的效率。而TCP的keep-alive是TCP的一种检测TCP连接状况的保鲜机制，注意两者区分。</p><p>Http1.1之前（未显示指定Connection:keep-alive）每个http请求都要求打开一个tcp socket连接，并且使用一次之后就断开这个tcp连接。对于如今这种一个页面少则几个多则几十几百个的请求的现状来说这显然不是一种高效的使用方式，http1.1之后默认开启keep-alive，通过使用keep-alive机制，可以减少tcp连接建立次数，以此提高性能和提高http服务器的吞吐率(更少的tcp连接意味着更少的系统内核调用,socket的accept()和close()调用。</p><p>然而keep-alive如果配置不当同样存在风险，长时间的tcp连接容易导致系统资源无效占用。正确地设置keep-alive timeout时间非常重要。那么是否是因为keep-alive超时，发起的主动关闭连接呢？结合tcpdump结果分析</p><p><img src="https://icecrea-1255483371.cos.ap-beijing.myqcloud.com/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/closewait%E6%8A%93%E5%8C%85%E7%BB%93%E6%9E%9C.png" alt></p><p>此处我使用wireshark，对上面的抓包结果分析，从图中圈红部分我们可以发现，最后一次ACK和发起主动关闭间隔30s，多个case结果均相同。那么对应的远程主机，也就是ng的keep-alive timeout应该是30，跟运维确认ng配置，得到验证<code>keepalive_timeout  30;  client_body_timeout 30s; client_header_timeout 30s;</code></p><h4 id="TCP连接与Finalize机制"><a href="#TCP连接与Finalize机制" class="headerlink" title="TCP连接与Finalize机制"></a>TCP连接与Finalize机制</h4><p>在观察监控时，还发现一个奇怪的现象，每过5分钟，CLOSE-WAIT的量变断崖式下降。第一反应是否是系统GC掉了？观察GC日志，发现时间点吻合。CLOSE_WAIT变更为LAST_ACK的tcp连接，同时都伴随着gc的发生。</p><p>为什么gc会导致tcp连接的关闭呢？这是就不得不提java的finalize机制。</p><blockquote><p>finalize()方法的工作原理：<br>触发gc时，一旦垃圾回收器准备好释放对象占用的存储空间，如果该对象未重写finalize()方法则可以直接回收，否则会去调用finalize()方法进行一些必要的清理工作。只有到下一次再进行垃圾回收动作的时候，才会真正释放这个对象所占用的内存空间。</p></blockquote><blockquote><p>假定你的对象（并非使用new方法）获得了一块“特殊”的内存区域，由于垃圾回收器只知道那些显示地经由new分配的内存空间，所以它不知道该如何释放这块“特殊”的内存区域，那么这个时候java允许在类中定义一个由finalize()方法，通过这个方法安全的回收“特殊”区域，特殊区域如文件(如java.util.zip.ZipFile)、流(如org.apache.commons.io.input.AutoCloseInputStream)、管道(如java.net.AbstractPlainSocketImpl)等。</p></blockquote><p>apache的httpclient的使用的就是<code>java.net.AbstractPlainSocketImpl</code>(调用的是<code>java.net.SocksSocketImpl，AbstractPlainSocketImpl</code>的子类)中的关闭方法</p><pre><code>protected void finalize() throws IOException {    close();}protected void close() throws IOException {    if (cmdsock != null)        cmdsock.close();    cmdsock = null;    super.close();}</code></pre>]]></content>
      
      
      <categories>
          
          <category> 计算机网络 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 计算机网络 </tag>
            
            <tag> TCP </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Hexo+Github搭建博客指南</title>
      <link href="/2019/09/27/da-jian-bo-ke/"/>
      <url>/2019/09/27/da-jian-bo-ke/</url>
      
        <content type="html"><![CDATA[<h2 id="安装Nodejs"><a href="#安装Nodejs" class="headerlink" title="安装Nodejs"></a>安装Nodejs</h2><p>安装Nodejs 稳定版：<br><a href="https://link.zhihu.com/?target=https%3A//nodejs.org/dist/v9.11.1/node-v9.11.1-x64.msi" target="_blank" rel="noopener">https://link.zhihu.com/?target=https%3A//nodejs.org/dist/v9.11.1/node-v9.11.1-x64.msi</a></p><h2 id="安装Hexo"><a href="#安装Hexo" class="headerlink" title="安装Hexo"></a>安装Hexo</h2><p>进入博客目录(如e:/blog) 右键git bash<br>npm i hexo-cli -g安装Hexo<br>hexo -v验证是否安装成功。<br>hexo init初始化文件夹<br>npm install安装必备的组件。<br>hexo g生成静态网页，每次改动要生成一下<br>hexo s打开本地服务器预览，浏览器打开<a href="http://localhost:4000/" target="_blank" rel="noopener">http://localhost:4000/</a></p><p>修改博客根目录下的_config.yml文件，repositrory改成github上对应项目地址</p><pre><code>deploy:  type: git  repository: git@github.com:icecrea/icecrea.github.io.git  branch: master</code></pre><h2 id="写文章，发布文章"><a href="#写文章，发布文章" class="headerlink" title="写文章，发布文章"></a>写文章，发布文章</h2><p>进入博客目录(如e:/blog) 右键git bash<br>安装扩展npm i hexo-deployer-git<br>输入hexo new post “article title”，新建文章<br>hexo d上传到github上</p><h2 id="指定git账户名"><a href="#指定git账户名" class="headerlink" title="指定git账户名"></a>指定git账户名</h2><p>在_config.yml中设置</p><pre><code># You can use this:deploy:  type: git  repo: &lt;repository url&gt;  branch: [branch]  message: [message]  name: [git user]  email: [git email]  extend_dirs: [extend directory]</code></pre><p>注意： 如果.deploy_git目录已经生成的情况下，需要删掉整个目录，再执行一次hexo d才行</p><h2 id="主题更换"><a href="#主题更换" class="headerlink" title="主题更换"></a>主题更换</h2><p>项目推荐 ：<a href="https://github.com/blinkfox/hexo-theme-matery/blob/develop/README_CN.md" target="_blank" rel="noopener">https://github.com/blinkfox/hexo-theme-matery/blob/develop/README_CN.md</a></p><p>参考： <a href="https://zhuanlan.zhihu.com/p/35668237" target="_blank" rel="noopener">https://zhuanlan.zhihu.com/p/35668237</a></p>]]></content>
      
      
      <categories>
          
          <category> 博客 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 博客 </tag>
            
        </tags>
      
    </entry>
    
    
  
  
</search>
