<?xml version="1.0" encoding="utf-8"?>
<search> 
  
  
    
    <entry>
      <title>类加载流程与顺序详解</title>
      <link href="/2019/10/13/lei-jia-zai/"/>
      <url>/2019/10/13/lei-jia-zai/</url>
      
        <content type="html"><![CDATA[<h2 id="类加载"><a href="#类加载" class="headerlink" title="类加载"></a>类加载</h2><p>类从被加载到虚拟机内存到卸出内存为止，它的整个生命周期<br><img src="https://icecrea-1300414836.file.myqcloud.com/jvm/load_class.png" alt><br>虚拟机规范中并没有强制约束何时进行加载，但是规范严格规定了有且只有下列五种情况必须对类进行初始化（加载、验证、准备都会随着发生）：</p><ol><li><p>遇到 new、getstatic、putstatic、invokestatic 这四条字节码指令时，如果类没有进行过初始化，则必须先触发其初始化。最常见的生成这 4 条指令的场景是：</p><ul><li>使用 new 关键字实例化对象的时候</li><li>读取或设置一个类的静态字段的时候（被 final 修饰、已在编译器把结果放入常量池的静态字段除外）</li><li>调用一个类的静态方法的时候</li></ul></li><li><p>使用 java.lang.reflect 包的方法对类进行反射调用的时候，如果类没有进行初始化，则需要先触发其初始化。</p></li><li><p>当初始化一个类的时候，如果发现其父类还没有进行过初始化，则需要先触发其父类的初始化。</p></li><li><p>当虚拟机启动时，用户需要指定一个要执行的主类（包含 main() 方法的那个类），虚拟机会先初始化这个主类；</p></li><li><p>当使用 JDK.7 的动态语言支持时，如果一个 java.lang.invoke.MethodHandle 实例最后的解析结果为REF_getStatic, REF_putStatic, REF_invokeStatic<br>的方法句柄，并且这个方法句柄所对应的类没有进行过初始化，则需要先触发其初始化；</p></li></ol><h4 id="加载阶段："><a href="#加载阶段：" class="headerlink" title="加载阶段："></a>加载阶段：</h4><p>加载过程完成以下三件事：</p><ol><li>通过一个<strong>类的全限定名</strong>来获取定义此类的<strong>二进制字节流</strong>。</li><li>将这个字节流所代表的<strong>静态存储结构</strong>转化为<strong>方法区的运行时存储结构</strong>。 </li><li>在内存中生成一个代表这个<strong>类的 Class 对象</strong>，作为方法区这个类的各种数据的访问入口。</li></ol><blockquote><p> 其中二进制字节流可以从以下方式中获取：</p><ul><li>从 ZIP 包读取，这很常见，最终成为日后 JAR、EAR、WAR 格式的基础。</li><li>从网络中获取，这种场景最典型的应用是 Applet。</li><li>运行时计算生成，这种场景使用得最多得就是动态代理技术，在 java.lang.reflect.Proxy 中，就是用了 ProxyGenerator.generateProxyClass 的代理类的二进制字节流。</li><li>由其他文件生成，典型场景是 JSP 应用，即由 JSP 文件生成对应的 Class 类。</li></ul></blockquote><p>加载阶段即可以使用系统提供的类加载器在完成，也可以由用户自定义的类加载器来完成。加载阶段与连接阶段的部分内容(如一部分字节码文件格式验证动作)是交叉进行的，加载阶段尚未完成，连接阶段可能已经开始。</p><h4 id="验证阶段"><a href="#验证阶段" class="headerlink" title="验证阶段"></a>验证阶段</h4><p>确保Class文件的字节流中包含的信息符合当前虚拟机的要求，并且不会危害虚拟机自身的安全。<br>整体分为4个阶段的校验工作：<strong>文件格式、元数据、字节码、符号引用</strong></p><h4 id="准备阶段"><a href="#准备阶段" class="headerlink" title="准备阶段"></a>准备阶段</h4><p>准备阶段是正式为<strong>类变量(static 成员变量)分配内存</strong>并设置类变量初始值（零值）的阶段，这些变量所使用的内存都将在方法区中进行分配。<br>这时候进行内存分配的仅包括类变量，而不包括实例变量，实例变量将会在对象实例化时随着对象一起分配在堆中。<br>其次，这里所说的初始值“通常情况”下是数据类型的零值，假设一个类变量的定义为：<br><code>public static int value=123;</code><br>那么，变量value在准备阶段过后的值为0而不是123。因为这时候尚未开始执行任何java方法，而<strong>把value赋值为123的putstatic指令是程序被编译后，存放于类构造器方法()之中</strong>，所以把value赋值为123的动作将在初始化阶段才会执行。<br>至于“特殊情况”是指：当类字段的字段属性是ConstantValue时，会在准备阶段初始化为指定的值，所以标注为final之后，value的值在准备阶段初始化为123而非0。</p><h4 id="解析阶段"><a href="#解析阶段" class="headerlink" title="解析阶段"></a>解析阶段</h4><p>　解析阶段是虚拟机将常量池内的符号引用替换为直接引用的过程。解析动作主要针对类或接口、字段、类方法、接口方法、方法类型、方法句柄和调用点限定符7类符号引用进行。</p><p>####初始化阶段<br>初始化阶段才真正开始执行类中的定义的 Java 程序代码。<strong>初始化阶段即虚拟机执行类构造器 () 方法的过程。</strong>在准备阶段，类变量已经赋过一次系统要求的初始值，而在初始化阶段，根据程序员通过程序制定的主观计划去初始化类变量和其它资源。<br><code>&lt;init&gt;()</code>方法具有以下特点：<br><strong>由编译器自动收集类中所有类变量的赋值动作和静态语句块（static{} 块）中的语句合并产生的，编译器收集的顺序由语句在源文件中出现的顺序决定。</strong><br>特别注意的是，静态语句块只能访问到定义在它之前的类变量，定义在它之后的类变量只能赋值，不能访问。</p><pre><code>  static {        i = 0;        //静态语句块只能访问到定义在它之前的类变量，定义在它之后的类变量只能赋值，不能访问。        //编译报错： Illegal forward reference        System.out.println(i);    }    static int i =1;</code></pre><p>虚拟机会自动保证在子类的<code>&lt;init&gt; ()</code>方法运行之前，父类的<br><code>&lt;init&gt;()</code> 方法已经执行结束。因此虚拟机中第一个执行<code>&lt;init&gt; ()</code> 方法的类肯定为<br>java.lang.Object。由于父类的<code>&lt;init&gt; ()</code>方法先执行，也就意味着父类中定义的静态语句块要优于子类的变量赋值操作。</p><p>注意：<br>所有引用类的方式都不会触发初始化称为被动引用，下面是3个被动引用例子：</p><ol><li>通过子类引用父类静态字段，不会导致子类初始化；</li><li>通过数组定义引用类，不会触发此类的初始化</li><li>常量在编译阶段会存入调用类的常量池中，本质上并没有直接引用定义常量的类，因此不会触发定义常量的类的初始化</li></ol><pre class="line-numbers language-java"><code class="language-java"><span class="token keyword">public</span> <span class="token keyword">class</span> <span class="token class-name">SuperClass</span> <span class="token punctuation">{</span>    <span class="token keyword">public</span> <span class="token keyword">static</span> <span class="token keyword">final</span> String HELLO <span class="token operator">=</span> <span class="token string">"hello"</span><span class="token punctuation">;</span>    <span class="token keyword">static</span> <span class="token punctuation">{</span>        System<span class="token punctuation">.</span>out<span class="token punctuation">.</span><span class="token function">println</span><span class="token punctuation">(</span><span class="token string">"super static class"</span><span class="token punctuation">)</span><span class="token punctuation">;</span>    <span class="token punctuation">}</span>    <span class="token keyword">public</span> <span class="token keyword">static</span> <span class="token keyword">int</span> value <span class="token operator">=</span> <span class="token number">123</span><span class="token punctuation">;</span><span class="token punctuation">}</span><span class="token keyword">public</span> <span class="token keyword">class</span> <span class="token class-name">SubClass</span> <span class="token keyword">extends</span> <span class="token class-name">SuperClass</span><span class="token punctuation">{</span>    <span class="token keyword">static</span> <span class="token punctuation">{</span>        System<span class="token punctuation">.</span>out<span class="token punctuation">.</span><span class="token function">println</span><span class="token punctuation">(</span><span class="token string">"sub static class"</span><span class="token punctuation">)</span><span class="token punctuation">;</span>    <span class="token punctuation">}</span><span class="token punctuation">}</span><span class="token keyword">public</span> <span class="token keyword">class</span> <span class="token class-name">Main</span> <span class="token punctuation">{</span>    <span class="token keyword">public</span> <span class="token keyword">static</span> <span class="token keyword">void</span> <span class="token function">main</span><span class="token punctuation">(</span>String<span class="token punctuation">[</span><span class="token punctuation">]</span> args<span class="token punctuation">)</span> <span class="token punctuation">{</span>        <span class="token comment" spellcheck="true">// 被动引用1 ：子类加载父类静态块，不会导致子类初始化；</span>        System<span class="token punctuation">.</span>out<span class="token punctuation">.</span><span class="token function">println</span><span class="token punctuation">(</span>SubClass<span class="token punctuation">.</span>value<span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token comment" spellcheck="true">// 被动引用2 ： 通过数组定义引用类，不会触发此类的初始化</span>        <span class="token comment" spellcheck="true">// 触发的是一个虚拟机自动生成的，直接继承于java.lang.Object的子类，创建动作由字节码指令newarray触发。并没有触发真正的SuperClass的初始化</span>        SuperClass<span class="token punctuation">[</span><span class="token punctuation">]</span> sca <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">SuperClass</span><span class="token punctuation">[</span><span class="token number">10</span><span class="token punctuation">]</span><span class="token punctuation">;</span>        <span class="token comment" spellcheck="true">// 被动引用3 ： 常量在编译阶段会存入调用类的常量池中，本质上并没有直接引用定义常量的类，因此不会触发定义常量的类的初始化</span>        System<span class="token punctuation">.</span>out<span class="token punctuation">.</span><span class="token function">println</span><span class="token punctuation">(</span>SuperClass<span class="token punctuation">.</span>HELLO<span class="token punctuation">)</span><span class="token punctuation">;</span>    <span class="token punctuation">}</span><span class="token punctuation">}</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h4 id="使用阶段"><a href="#使用阶段" class="headerlink" title="使用阶段"></a>使用阶段</h4><h4 id="卸载化阶段"><a href="#卸载化阶段" class="headerlink" title="卸载化阶段"></a>卸载化阶段</h4><h4 id="例子："><a href="#例子：" class="headerlink" title="例子："></a>例子：</h4><pre class="line-numbers language-java"><code class="language-java"><span class="token keyword">public</span> <span class="token keyword">class</span> <span class="token class-name">Singleton</span> <span class="token punctuation">{</span>    <span class="token comment" spellcheck="true">// step 1</span>    <span class="token keyword">private</span> <span class="token keyword">static</span> Singleton singleton <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">Singleton</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>    <span class="token keyword">public</span> <span class="token keyword">static</span> <span class="token keyword">int</span> count1<span class="token punctuation">;</span>    <span class="token comment" spellcheck="true">// step 2</span>    <span class="token comment" spellcheck="true">// 准备阶段值均为0 赋值为5的pustatic指令，存放于类构造器方法中，初始化阶段执行</span>    <span class="token keyword">public</span> <span class="token keyword">static</span> <span class="token keyword">int</span> count2 <span class="token operator">=</span> <span class="token number">5</span><span class="token punctuation">;</span>    <span class="token comment" spellcheck="true">// step 1.2</span>    <span class="token keyword">private</span> <span class="token function">Singleton</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>        count1<span class="token operator">++</span><span class="token punctuation">;</span>        count2<span class="token operator">++</span><span class="token punctuation">;</span>        System<span class="token punctuation">.</span>out<span class="token punctuation">.</span><span class="token function">println</span><span class="token punctuation">(</span><span class="token string">"constructor init :"</span> <span class="token operator">+</span> count1 <span class="token operator">+</span> <span class="token string">" ---"</span> <span class="token operator">+</span> count2<span class="token punctuation">)</span><span class="token punctuation">;</span>        System<span class="token punctuation">.</span>out<span class="token punctuation">.</span><span class="token function">println</span><span class="token punctuation">(</span><span class="token string">"constructor init"</span><span class="token punctuation">)</span><span class="token punctuation">;</span>    <span class="token punctuation">}</span>    <span class="token comment" spellcheck="true">// step 1.1</span>    <span class="token comment" spellcheck="true">// 对象一建立就运行构造代码块了，而且优先于构造函数执行。有对象建立，才会运行构造代码块</span>    <span class="token punctuation">{</span>        System<span class="token punctuation">.</span>out<span class="token punctuation">.</span><span class="token function">println</span><span class="token punctuation">(</span><span class="token string">"init :"</span> <span class="token operator">+</span> count1 <span class="token operator">+</span> <span class="token string">" ---"</span> <span class="token operator">+</span> count2<span class="token punctuation">)</span><span class="token punctuation">;</span>        System<span class="token punctuation">.</span>out<span class="token punctuation">.</span><span class="token function">println</span><span class="token punctuation">(</span><span class="token string">"init"</span><span class="token punctuation">)</span><span class="token punctuation">;</span>    <span class="token punctuation">}</span>    <span class="token comment" spellcheck="true">// step 3</span>    <span class="token keyword">static</span> <span class="token punctuation">{</span>        System<span class="token punctuation">.</span>out<span class="token punctuation">.</span><span class="token function">println</span><span class="token punctuation">(</span><span class="token string">"static init"</span> <span class="token operator">+</span> count1 <span class="token operator">+</span> <span class="token string">" ---"</span> <span class="token operator">+</span> count2<span class="token punctuation">)</span><span class="token punctuation">;</span>        System<span class="token punctuation">.</span>out<span class="token punctuation">.</span><span class="token function">println</span><span class="token punctuation">(</span><span class="token string">"static init"</span><span class="token punctuation">)</span><span class="token punctuation">;</span>    <span class="token punctuation">}</span>    <span class="token keyword">public</span> <span class="token keyword">static</span> Singleton <span class="token function">getInstance</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>        <span class="token keyword">return</span> singleton<span class="token punctuation">;</span>    <span class="token punctuation">}</span>    <span class="token keyword">public</span> <span class="token keyword">static</span> <span class="token keyword">void</span> <span class="token function">main</span><span class="token punctuation">(</span>String<span class="token punctuation">[</span><span class="token punctuation">]</span> args<span class="token punctuation">)</span> <span class="token punctuation">{</span>        Singleton singleton <span class="token operator">=</span> Singleton<span class="token punctuation">.</span><span class="token function">getInstance</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        System<span class="token punctuation">.</span>out<span class="token punctuation">.</span><span class="token function">println</span><span class="token punctuation">(</span>Singleton<span class="token punctuation">.</span>count1<span class="token punctuation">)</span><span class="token punctuation">;</span>        System<span class="token punctuation">.</span>out<span class="token punctuation">.</span><span class="token function">println</span><span class="token punctuation">(</span>Singleton<span class="token punctuation">.</span>count2<span class="token punctuation">)</span><span class="token punctuation">;</span>    <span class="token punctuation">}</span><span class="token punctuation">}</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>参考：<br><a href="https://juejin.im/post/5b2357c5f265da597a60f9ec" target="_blank" rel="noopener">https://juejin.im/post/5b2357c5f265da597a60f9ec</a></p>]]></content>
      
      
      <categories>
          
          <category> JVM </category>
          
      </categories>
      
      
        <tags>
            
            <tag> JVM </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Mysql排序是如何实现的？</title>
      <link href="/2019/10/12/mysql-pai-xu-shi-ru-he-shi-xian-de/"/>
      <url>/2019/10/12/mysql-pai-xu-shi-ru-he-shi-xian-de/</url>
      
        <content type="html"><![CDATA[<h2 id="Mysql排序是如何实现的？"><a href="#Mysql排序是如何实现的？" class="headerlink" title="Mysql排序是如何实现的？"></a>Mysql排序是如何实现的？</h2><h3 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h3><pre><code>表定义CREATE TABLE `t` (  `id` int(11) NOT NULL,  `city` varchar(16) NOT NULL,  `name` varchar(16) NOT NULL,  `age` int(11) NOT NULL,  `addr` varchar(128) DEFAULT NULL,  PRIMARY KEY (`id`),  KEY `city` (`city`)) ENGINE=InnoDB;</code></pre><p>执行语句<code>select city,name,age from t where city=&#39;杭州&#39; order by name limit 1000 ;</code> 里面用到了排序，它是如何执行的呢？</p><h3 id="全字段排序策略"><a href="#全字段排序策略" class="headerlink" title="全字段排序策略"></a>全字段排序策略</h3><p>通过explain分析，看到Extra 这个字段有“Using filesort”，表示的就是需要排序，MySQL 会给每个线程分配一块内存用于排序，称为 <code>sort_buffer</code>。</p><p>通常情况下，执行流程为：</p><ul><li>初始化sort_buffer，放入city,name,age三个字段，</li><li>从索引 city 找到第一个满足 city=’杭州’条件的主键 id，回表取出整行，取 name、city、age 三个字段的值，存入 sort_buffer 中。重复该步骤取下一条记录直到不满足查询条件</li><li>对sort_buffer中数据按name做快速排序</li><li>按排序结果取前1000行返回客户端</li></ul><p>“按 name 排序”这个动作，如果要排序的数据量小于 sort_buffer_size，排序就在内存中完成。否则会使用磁盘临时文件辅助排序。</p><h3 id="rowid排序策略"><a href="#rowid排序策略" class="headerlink" title="rowid排序策略"></a>rowid排序策略</h3><p>对全字段排序来说，如果查询字段太多，sort_buffer不足，分成临时文件排序会导致性能很差。</p><p>如果 MySQL 认为排序的单行长度太大会怎么做呢？可以通过修改参数，让mysql采取另一种算法</p><pre class="line-numbers language-sql"><code class="language-sql"><span class="token keyword">SET</span> max_length_for_sort_data <span class="token operator">=</span> <span class="token number">16</span><span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p><code>max_length_for_sort_data</code>，是 MySQL 中专门控制用于排序的行数据的长度的一个参数。它的意思是，如果单行的长度超过这个值，MySQL 就认为单行太大，要换一个算法。city、name、age 这三个字段的定义总长度是 36，可以设置为16来验证变化。</p><p>执行流程为：</p><ul><li>初始化sort_buffer，放入name，id两个字段，</li><li>从索引 city 找到第一个满足 city=’杭州’条件的主键 id，回表取出整行，取 name、id 的值，存入 sort_buffer 中。重复该步骤取下一条记录直到不满足查询条件</li><li>对sort_buffer中数据按name做快速排序</li><li>按排序结果取前1000行，并按照id的值回到原表取city,name,age三个字段给客户端</li></ul><p>可以看出，比全字段排序多了一次回表，从sort_buffer排序后，还需要再回主键索引取其它需要的值。</p><h3 id="全字段排序与rowid排序比较"><a href="#全字段排序与rowid排序比较" class="headerlink" title="全字段排序与rowid排序比较"></a>全字段排序与rowid排序比较</h3><p>MySQL 的一个设计思想：<strong>如果内存够，就要多利用内存，尽量减少磁盘访问。</strong></p><p>对于 <strong>InnoDB 表</strong>来说，rowid 排序会要求回表多造成磁盘读，因此不会被优先选择。<br>可以想到，对于内存表，回表过程只是简单地根据数据行的位置，直接访问内存得到数据，不会导致多访问磁盘。</p><p>当然，并不是所有order by 都需要排序操作，MySQL 之所以需要生成临时表，并且在临时表上做排序操作，其原因是原来的数据都是无序的。对本文例子来说，如果从 city 这个索引上取出来的行，天然就是按照 name 递增排序的话还需要排序呢？</p><p>假如有(city, name)联合索引，在这个索引里面，我们依然可以用树搜索的方式定位到第一个满足 city=’杭州’的记录，并且额外确保了，接下来按顺序取“下一条记录”的遍历过程中，只要 city 的值是杭州，name 的值就一定是有序的。查询过程不需要临时表，也不需要排序。Extra 字段中没有 Using filesort 了，也就是不需要排序了。</p><p>参考：<br>丁奇：mysql实战45讲</p>]]></content>
      
      
      <categories>
          
          <category> MYSQL </category>
          
      </categories>
      
      
        <tags>
            
            <tag> MYSQL </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>count函数性能比较与优化设计</title>
      <link href="/2019/10/11/count-han-shu-xing-neng-bi-jiao-yu-you-hua-she-ji/"/>
      <url>/2019/10/11/count-han-shu-xing-neng-bi-jiao-yu-you-hua-she-ji/</url>
      
        <content type="html"><![CDATA[<h2 id="count函数性能比较与优化设计"><a href="#count函数性能比较与优化设计" class="headerlink" title="count函数性能比较与优化设计"></a>count函数性能比较与优化设计</h2><h3 id="count-如何实现？"><a href="#count-如何实现？" class="headerlink" title="count(*)如何实现？"></a>count(*)如何实现？</h3><p>count(*) 在不同的搜索引擎中，实现不同。MyISAM将一个表的总行数存在了磁盘可以直接返回，InnoDB需要一行一行从引擎读取累计计数。</p><h3 id="为什么innodb不存下表的总行数"><a href="#为什么innodb不存下表的总行数" class="headerlink" title="为什么innodb不存下表的总行数?"></a>为什么innodb不存下表的总行数?</h3><p>对于Innodb来说，即使是在同一个时刻的多个查询，由于多版本并发控制（MVCC）的原因，同样的查询返回的结果也可能不同，比如InnoDB 表“应该返回多少行”也是不确定的。如下图<br><img src="https://icecrea-1300414836.cos.ap-beijing.myqcloud.com/mysql/mysql45/14_count/count_method_not_equal.png" alt></p><p>这和 InnoDB 的事务设计有关系，可重复读是它默认的隔离级别，在代码上就是通过多版本并发控制，也就是 MVCC 来实现的。每一行记录都要判断自己是否对这个会话可见，因此对于 count(*) 请求来说，InnoDB 只好把数据一行一行地读出依次判断，可见的行才能够用于计算“基于这个查询”的表的总行数。</p><h3 id="count-做了哪些优化？"><a href="#count-做了哪些优化？" class="headerlink" title="count(*)做了哪些优化？"></a>count(*)做了哪些优化？</h3><ol><li>遍历最小的索引树<br>InnoDB 是索引组织表，主键索引树的叶子节点是数据，而普通索引树的叶子节点是主键值。所以，普通索引树比主键索引树小很多。对于 count(*) 这样的操作，遍历哪个索引树得到的结果逻辑上都是一样的。因此，MySQL 优化器会找到最小的那棵树来遍历。</li><li>不会把全部字段取出来，不取值，按行累加。</li></ol><h3 id="如果经常查询记录总数，应该如何设计优化？"><a href="#如果经常查询记录总数，应该如何设计优化？" class="headerlink" title="如果经常查询记录总数，应该如何设计优化？"></a>如果经常查询记录总数，应该如何设计优化？</h3><p>首先，需要自己计数。<br><strong>方案一：使用redis缓存存储。</strong><br>缺陷：存在逻辑上不精确，数据不一致问题。</p><p>假设我们有页面，展示最新100条数据与总行数。我们通过查询redis计数与查询最新100条记录实现该功能。单独使用是没问题的。如果同时有另一个会话进行插入，就会因为时序导致数据不一致问题。</p><p>假设先插入数据，后redis+1。在两者执行中间访问页面。如下表。此时插入数据生效，redis未变化，导致最新100条记录正确，总行数错误。<br>| 时刻      |    会话A | 会话B |<br>| :——– | ——–:| :–: |<br>| T1  | 插入一行数据 |    |<br>| T2 |  |  读redis计数，查询最新100条记录   |<br>| T3  | redis计数加1 |    |</p><p>如果新增操作时序反过来，先redis+1后新增，就会存在总行数正确，最新100条未更新的情况。同样数据不一致。</p><p><strong>方案二、在数据库保存计数</strong><br>把这个计数直接放到数据库里单独的一张计数表 C 中。<br>首先，这解决了崩溃丢失的问题，InnoDB 是支持崩溃恢复不丢数据的。<br>其次，对于方案一的数据不一致问题，我们可以利用“事务”特性解决<br><img src="https://icecrea-1300414836.cos.ap-beijing.myqcloud.com/mysql/mysql45/14_count/count_method_not_equal.png" alt></p><p>如图。会话 B 的读操作仍然是在 T3 执行的，但是因为这时候更新事务还没有提交，所以计数值加 1 这个操作对会话 B 还不可见。因此，会话 B 看到的结果里， 查计数值和“最近 100 条记录”看到的结果，逻辑上就是一致的。</p><h3 id="count-count-id-count-1-count-字段-性能差别？"><a href="#count-count-id-count-1-count-字段-性能差别？" class="headerlink" title="count(*),count(id),count(1),count(字段) 性能差别？"></a>count(*),count(id),count(1),count(字段) 性能差别？</h3><p>首先要清楚 count() 的语义。count() 是一个聚合函数，对于返回的结果集，一行行地判断，如果 count 函数的参数不是 NULL，累计值就加 1，否则不加。最后返回累计值。</p><p>先说结论，<strong>效率从低到高：count(字段)&lt;count(主键 id)&lt;count(1)≈count(*)</strong></p><p><strong>对count(字段)来说：</strong></p><ol><li>字段定义not null，一行行地从记录里面读出这个字段，判断为不能是 null，按行累加</li><li>字段允许null，判断为可能是 null，还要把值取出来再判断一下，不是 null 才累加。</li></ol><p>count(字段)效率最低，因为它表示返回满足条件的数据行里面，参数“字段”不为 NULL 的总个数。而其它三个表示返回满足条件的结果集的总行数。同时取值操作，拷贝字段操作耗时。</p><p><strong>对于 count(主键 id) 来说：</strong><br>InnoDB 引擎会遍历整张表，把每一行的 id 值都取出来，返回给 server 层。server 层拿到 id 后，判断是不可能为空的，就按行累加。<br>性能不高，因为需要<strong>从引擎返回 id 会涉及到解析数据行，以及拷贝字段值的操作。</strong></p><p><strong>对于 count(1) 来说：</strong><br>InnoDB 引擎遍历整张表，但不取值。server 层对于返回的每一行，放一个数字“1”进去，判断是不可能为空的，按行累加。</p><p><strong>对于count(*) 来说：</strong><br>不会把全部字段取出来，而是专门做了优化，不取值。count(*) 肯定不是 null，按行累加。</p>]]></content>
      
      
      <categories>
          
          <category> MYSQL </category>
          
      </categories>
      
      
        <tags>
            
            <tag> MYSQL </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>InnoDB刷脏页策略 - 为什么我的Mysql会抖一下</title>
      <link href="/2019/10/10/innodb-shua-zang-ye-ce-lue-wei-shi-me-wo-de-mysql-hui-dou-yi-xia/"/>
      <url>/2019/10/10/innodb-shua-zang-ye-ce-lue-wei-shi-me-wo-de-mysql-hui-dou-yi-xia/</url>
      
        <content type="html"><![CDATA[<h2 id="InnoDB刷脏页策略-为什么我的Mysql会抖一下"><a href="#InnoDB刷脏页策略-为什么我的Mysql会抖一下" class="headerlink" title="InnoDB刷脏页策略 - 为什么我的Mysql会抖一下"></a>InnoDB刷脏页策略 - 为什么我的Mysql会抖一下</h2><h3 id="什么是脏页？为什么会有脏页？"><a href="#什么是脏页？为什么会有脏页？" class="headerlink" title="什么是脏页？为什么会有脏页？"></a>什么是脏页？为什么会有脏页？</h3><p>前文已介绍过，Mysql有Write Ahead Logging 机制，InnoDB 在处理更新语句的时候，只做了写日志redo log这一个磁盘操作。而将内存里的数据写入磁盘的过程，术语就是 <code>flush</code>。在flush 操作执行之前，内存与磁盘数据是不一致的。</p><blockquote><p>当内存数据页跟磁盘数据页内容不一致的时候，我们称这个内存页为“脏页”。<br>内存数据写入到磁盘后，内存和磁盘上的数据页的内容就一致了，称为“干净页”。</p></blockquote><h3 id="什么情况下会刷脏页？"><a href="#什么情况下会刷脏页？" class="headerlink" title="什么情况下会刷脏页？"></a>什么情况下会刷脏页？</h3><p>刷脏页有下列四种场景：<br><strong>一、 redo log 写满了，要 flush 脏页</strong><br><img src="https://icecrea-1300414836.cos.ap-beijing.myqcloud.com/mysql/mysql45/12_flush/redolog.jpg" alt><br>redo log 写满了，系统会停止所有更新操作，把 checkpoint 往前推进，redo log 留出空间可以继续写。<br>checkpoint 位置从 CP 推进到 CP’，就需要将两个点之间的日志（浅绿色部分），对应的所有脏页都 flush 到磁盘上。之后，图中从 write pos 到 CP’之间就是可以再写入的 redo log 的区域。<br>innodb要尽量避免，会堵住所有更新。</p><p><strong>二、内存不够用了，要先将脏页写到磁盘 **<br>这种情况是常态。</strong>InnoDB 用缓冲池（buffer pool）管理内存**，缓冲池中的内存页有三种状态：</p><ol><li>还没有使用的；</li><li>使用了并且是干净页；</li><li>使用了并且是脏页。</li></ol><p>InnoDB 的策略是尽量使用内存，因此对于一个长时间运行的库来说，未被使用的页面很少。<br>而当要读入的数据页没有在内存的时候，就必须到缓冲池中申请一个数据页。这时候只能把<strong>最久不使用</strong>的数据页从内存中淘汰掉：如果要淘汰的是一个干净页，就直接释放出来复用；但<strong>如果是脏页呢，就必须将脏页先刷到磁盘，变成干净页后才能复用。</strong></p><p><strong>三、 mysql认为系统空闲，flush脏页</strong><br><strong>四、 mysql正常关闭</strong></p><p> 刷脏页虽然是常态，但是出现以下这两种情况会导致性能问题<br>    1. 一个查询要淘汰的脏页个数太多，会导致查询的响应时间明显变长；<br>    2. 日志写满，更新全部堵住，写性能跌为 0，这种情况对敏感业务来说，是不能接受的。</p><h3 id="InnoDB刷脏页控制策略与参数"><a href="#InnoDB刷脏页控制策略与参数" class="headerlink" title="InnoDB刷脏页控制策略与参数"></a>InnoDB刷脏页控制策略与参数</h3><p><code>innodb_io_capacity</code> 参数建议设置成磁盘的 IOPS</p><pre><code>#测试磁盘随机读写的命令fio -filename=$filename -direct=1 -iodepth 1 -thread -rw=randrw -ioengine=psync -bs=16k -size=500M -numjobs=10 -runtime=10 -group_reporting -name=mytest</code></pre><p><code>innodb_io_capacity</code> 设置错误案例：<br>主机磁盘用的是 SSD，但是<code>innodb_io_capacity</code>的值设置的是 300。于是，InnoDB 认为这个系统的能力就这么差，所以刷脏页刷得特别慢，甚至比脏页生成的速度还慢，这样就造成了脏页累积，影响了查询和更新性能。</p><p><strong>如果设计策略控制刷脏页的速度，应该参考哪些因素呢？</strong></p><p>刷太慢，会出现什么情况？首先是内存脏页太多，其次是 redo log 写满。所以，InnoDB 的刷盘速度就是要参考这两个因素：</p><ol><li>脏页比例</li><li>redo log 写盘速度。</li></ol><p><code>innodb_max_dirty_pages_pct</code>是脏页比例上限，默认值是 75%。<br>通过脏页比例和 redo log 写入速度算出来的两个值，取其中较大值R， 引擎就可以按照<code>innodb_io_capacity</code>定义的能力乘以 R% 来控制刷脏页的速度。</p><p>InnoDB 会在后台刷脏页，而刷脏页的过程是要将内存页写入磁盘。所以，无论是你的查询语句在需要内存的时候可能要求淘汰一个脏页，还是由于刷脏页的逻辑会占用 IO 资源并可能影响到了你的更新语句，都可能是造成你从业务端感知到 MySQL“抖”了一下的原因。</p><p><strong>刷脏页“连坐”参数</strong><br>MySQL 中的一个机制，在准备刷一个脏页的时候，如果这个数据页旁边的数据页刚好是脏页，就会把这个“邻居”也带着一起刷掉；而且这个把“邻居”拖下水的逻辑还可以继续蔓延，也就是对于每个邻居数据页，如果跟它相邻的数据页也还是脏页的话，也会被放到一起刷。InnoDB 中，<code>innodb_flush_neighbors = 1</code> 会有上述的“连坐”机制，为0不会。</p><p>这种机制在机械硬盘上，可以减少很多随机 IO，提升系统性能。而使用SSD这类IOPS高的设备，建议设置成0，此时IOPS 往往不是瓶颈，可以设置“只刷自己”减少 SQL 语句响应时间。</p>]]></content>
      
      
      <categories>
          
          <category> MYSQL </category>
          
      </categories>
      
      
        <tags>
            
            <tag> MYSQL </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Mysql唯一索引性能问题 - change buffer</title>
      <link href="/2019/10/08/mysql-wei-yi-suo-yin-xing-neng-wen-ti-change-buffer/"/>
      <url>/2019/10/08/mysql-wei-yi-suo-yin-xing-neng-wen-ti-change-buffer/</url>
      
        <content type="html"><![CDATA[<h2 id="Mysql唯一索引性能问题-change-buffer"><a href="#Mysql唯一索引性能问题-change-buffer" class="headerlink" title="Mysql唯一索引性能问题 - change buffer"></a>Mysql唯一索引性能问题 - change buffer</h2><p>Q：如果业务保证了唯一。从性能的角度考虑，选择唯一索引还是普通索引呢？</p><h3 id="查询过程："><a href="#查询过程：" class="headerlink" title="查询过程："></a>查询过程：</h3><blockquote><p>唯一索引：查找到第一个满足的条件就停止检索<br>普通索引：直到不满足条件时停止检索<br>性能差异：极低可忽略</p></blockquote><p>InnoDB 的数据是按<strong>数据页</strong>为单位来读写的。也就是说，当需要读一条记录的时候，并不是将这个记录本身从磁盘读出来，而是以页为单位，将其整体读入内存。<br>在 InnoDB 中，每个数据页的大小默认是 16KB。<br>因为引擎是按页读写的，所以说，当找到一条记录的时候，它所在的数据页就都在内存里了。那么，对于普通索引来说，要多做的那一次“查找和判断下一条记录”的操作，就只需要一次指针寻找和一次计算。如果刚好是该数据页最后一条记录，必须读下一数据页会稍微复杂。但其概率很小，如对于整型字段，一个数据页可以放仅千个key。</p><h3 id="更新过程："><a href="#更新过程：" class="headerlink" title="更新过程："></a>更新过程：</h3><p>change buffer介绍：</p><blockquote><p>当需要<strong>更新一个数据页</strong>时，如果数据页在内存中就直接更新，而<strong>如果这个数据页还没有在内存中的话，在不影响数据一致性的前提下，InooDB 会将这些更新操作缓存在 change buffer 中，这样就不需要从磁盘中读入这个数据页了。</strong>在下次查询需要访问这个数据页的时候，将数据页读入内存，然后执行 change buffer 中与这个页有关的操作。通过这种方式就能保证这个数据逻辑的正确性。</p><p>将 change buffer 中的操作应用到原数据页，得到最新结果的过程称为 merge。除了<strong>访问这个数据页</strong>会触发 merge 外，系统有后台线程会定期 merge。在数据库正常关闭（shutdown）的过程中，也会执行 merge 操作。</p></blockquote><p>可以推出：如果能够将更新操作先记录在 change buffer，减少读磁盘，语句的执行速度会得到明显的提升。而且，数据读入内存是需要占用 buffer pool 的，所以这种方式还能够避免占用内存，提高内存利用率。</p><p>唯一索引更新会先判断唯一性约束，必须要将数据页读入内存才能判断。因此不会使用change buffer。</p><p>change buffer 用的是 buffer pool 里的内存，因此不能无限增大。change buffer 的大小，可以通过参数 <code>innodb_change_buffer_max_size</code> 来动态设置。这个参数设置为 50 的时候，表示 change buffer 的大小最多只能占用 buffer pool 的 50%。</p><p>执行更新插入操作时，普通索引和唯一索引区别</p><ul><li>如果记录要更新的目标页在内存中，影响不大</li><li>如果记录要更新的目标页不在内存中<ul><li>唯一索引：需要<strong>将数据页读入内存</strong>。判断到没有冲突，插入这个值。</li><li>普通索引：将更新记录在 change buffer，语句执行就结束了。</li></ul></li></ul><p>将数据从磁盘读入内存涉及随机 IO 的访问，是数据库里面成本最高的操作之一。change buffer 因为减少了随机磁盘访问，所以对更新性能的提升是会很明显的。</p><h3 id="change-buffer-的使用场景"><a href="#change-buffer-的使用场景" class="headerlink" title="change buffer 的使用场景"></a>change buffer 的使用场景</h3><p>Q：普通索引的所有场景，使用 change buffer 都可以起到加速作用吗？</p><p>merge 的时候是真正进行数据更新的时刻，而 change buffer 的主要目的就是将记录的变更动作缓存下来，所以在一个数据页做 merge 之前，change buffer 记录的变更越多（也就是这个页面上要更新的次数越多），收益就越大。</p><ul><li>对于<strong>写多读少</strong>的业务来说，页面在写完以后马上被访问到的概率比较小，此时 change buffer 的使用效果最好。这种业务模型常见的就是<strong>账单类、日志类</strong>的系统。</li><li>对于<strong>更新后马上会查询</strong>的业务来说，随机访问 IO 的次数不会减少，反而增加了 change buffer 的维护代价。</li></ul><h3 id="change-buffer-与redo-log"><a href="#change-buffer-与redo-log" class="headerlink" title="change buffer 与redo log"></a>change buffer 与redo log</h3><p>Mysql中WAL技术，即<code>Write-aheading Logging</code>，关键点就是先写日志再写磁盘。如果每条更新都要写磁盘，磁盘找到记录再更新整个IO、查找成本都很高。所以更新操作时，先把记录写到redo log，并更新内存就算更新完成。在适当的时候将记录更新到磁盘。</p><p>如何理解change buffer 和 redo log的顺序？<br>假设语句<code>insert into t(id,k) values(id1,k1),(id2,k2);</code> 其中k1所在数据页在内存中，k2数据页不在<br>更新操作：</p><ol><li>k1对应Page 1在内存中直接更新内存</li><li>k2对应Page 2 没有在内存中，就在内存的 change buffer 区域，记录下“我要往 Page 2 插入一行”这个信息</li><li>将上述两个动作记入 redo log 中</li></ol><p>上述做完事务完成，更新的成本很低，写了两处内存，一处磁盘（两次操作合在一起写，还是顺序写）</p><p>如果后续读操作，假设此时内存中数据页还在：</p><ol><li>读page1直接从内存中返回。此处可能会疑惑，wal后是否一定要读盘，是否一定要从redo log里将数据更新后才返回。其实不需要，直接从内存返回结果</li><li>读 Page 2 的时候，需要把 Page 2 从磁盘读入内存中，然后应用 change buffer 里面的操作日志，生成一个正确的版本并返回结果。</li></ol><p>Q:如果某次写入使用了 change buffer 机制，之后主机异常重启，是否会丢失 change buffer 和数据?</p><p>不会丢失。虽然是只更新内存，但是在事务提交的时候，我们把 change buffer 的操作也记录到 redo log 里了，所以崩溃恢复的时候，change buffer 也能找回来。</p><h3 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h3><p>普通索引和唯一索引查询能力没差别，主要在更新性能影响。如果所有的更新后面马上伴随了查询，应该关闭change buffer。其它情况下change buffer会提高性能。如果碰上了大量插入数据慢、内存命中率低的时候，可以考虑唯一索引方向的排查思路。历史数据的归档库，可以考虑唯一索引改成普通索引。</p><p>参考：<br>丁奇Mysql45讲</p>]]></content>
      
      
      <categories>
          
          <category> MYSQL </category>
          
      </categories>
      
      
        <tags>
            
            <tag> MYSQL </tag>
            
            <tag> 索引 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Mysql一致性视图</title>
      <link href="/2019/10/07/mysql-yi-zhi-xing-shi-tu/"/>
      <url>/2019/10/07/mysql-yi-zhi-xing-shi-tu/</url>
      
        <content type="html"><![CDATA[<h2 id="Mysql一致性视图"><a href="#Mysql一致性视图" class="headerlink" title="Mysql一致性视图"></a>Mysql一致性视图</h2><h3 id="RC与RR的实现方式：一致性读视图"><a href="#RC与RR的实现方式：一致性读视图" class="headerlink" title="RC与RR的实现方式：一致性读视图"></a>RC与RR的实现方式：一致性读视图</h3><p>InnoDB在实现MVCC时用到<strong>一致性读视图</strong>，<code>consistent read view</code>，用于支持 RC（Read Committed，读提交）和 RR（Repeatable Read，可重复读）隔离级别的实现。它没有物理结构，作用是事务执行期间用来定义“我能看到什么数据”。</p><h3 id="快照在MVCC里是如何工作的？"><a href="#快照在MVCC里是如何工作的？" class="headerlink" title="快照在MVCC里是如何工作的？"></a>快照在MVCC里是如何工作的？</h3><p><strong>可重复读隔离级别下，事务在启动时拍了基于整库的快照。</strong><br>InnoDB 里面每个事务有一个唯一的事务 ID，叫作 transaction id。它是在事务开始的时候向 InnoDB 的事务系统申请的，是按申请顺序严格递增的。每行数据也都是有多个版本的。每次事务更新数据的时候，都会生成一个新的数据版本，并且把 transaction id 赋值给这个数据版本的事务 ID，记为 row trx_id。同时，旧的数据版本要保留，并且在新的数据版本中，能够有信息可以直接拿到它。（通过执行更新操作时生成的undo log回滚日志）</p><p>InnoDB 利用了“所有数据都有多个版本”的这个特性，实现了“秒级创建快照”的能力。</p><blockquote><p>可重复读的定义，一个事务启动的时候，能够看到所有已经提交的事务结果。但是之后，这个事务执行期间，其他事务的更新对它不可见。</p></blockquote><h3 id="事务的视图数组与数据版本row-trx-id"><a href="#事务的视图数组与数据版本row-trx-id" class="headerlink" title="事务的视图数组与数据版本row trx_id"></a>事务的视图数组与数据版本row trx_id</h3><p>在实现上， <strong>InnoDB 为每个事务构造了一个数组</strong>，用来保存这个<strong>事务启动瞬间</strong>，当前正在“活跃”的所有事务 ID。<br><strong>“活跃”指的就是，启动了但还没提交。</strong></p><blockquote><p>低水位：数组里面事务 ID 的最小值记。<br>高水位：当前系统里面已经创建过的事务 ID 的最大值加 1 。<br>视图数组和高水位，就组成了当前事务的一致性视图（read-view）。</p></blockquote><p><img src="https://icecrea-1300414836.cos.ap-beijing.myqcloud.com/mysql/mysql45/08_view/view.png" alt><br>一个数据版本的 row trx_id，有以下可能：</p><pre><code>1. 在绿色部分，表示这个版本是已提交的事务或者是当前事务自己生成的，这个数据是可见的；2. 如果落在红色部分，表示这个版本是由将来启动的事务生成的，是肯定不可见的；3. 如果落在黄色部分，那就包括两种情况    a. 若 row trx_id 在数组中，表示这个版本是由还没提交的事务生成的，不可见；    b. 若 row trx_id 不在数组中，表示这个版本是已经提交了的事务生成的，可见。</code></pre><h3 id="实战分析"><a href="#实战分析" class="headerlink" title="实战分析"></a>实战分析</h3><pre><code>mysql&gt; CREATE TABLE `t` (  `id` int(11) NOT NULL,  `k` int(11) DEFAULT NULL,  PRIMARY KEY (`id`)) ENGINE=InnoDB;insert into t(id, k) values(1,1),(2,2);</code></pre><p><img src="https://icecrea-1300414836.cos.ap-beijing.myqcloud.com/mysql/mysql45/08_view/case.png" alt><br>图中事务B查询结果为3，事务A查询结果为1。下面解释原因：</p><p>可以先做如下假设</p><pre><code>1. 事务 A 开始前，系统里面只有一个活跃事务 ID 是 99；2. 事务 A、B、C 的版本号分别是 100、101、102，且当前系统里只有这四个事务；3. 三个事务开始前，(1,1）这一行数据的 row trx_id 是 90。</code></pre><p>事务A的数组为[99,100]，事务B数组为[99,100,101]，事务C数组为[99,100,101,102]</p><p>事务 C先把数据从 (1,1) 改成了 (1,2)。这时候，这个数据的最新版本的 row trx_id 是 102，而 90 这个版本已经成为了历史版本。第二个有效更新是事务 B，把数据从 (1,2) 改成了 (1,3)。这时候，这个数据的最新版本（即 row trx_id）是 101，而 102 又成为了历史版本。row trx_id更新过程即为90-》102-》101。</p><pre><code>事务A读数据，A的视图数组是 [99,100]，1. 找到当前数据（1，3），row trx_id=101，比高水位大，处于红色区域，不可见；（版本未提交）2. 找到上一个历史版本，一看 row trx_id=102，比高水位大，处于红色区域，不可见；（版本视图创建后提交）3. 找到上一个历史版本（1,1)，它的 row trx_id=90，比低水位小，处于绿色区域，可见。</code></pre><p>更容易理解的分析方法：</p><pre><code>一个数据版本，对于一个事务视图来说，除了自己的更新总是可见以外，有三种情况：1. 版本未提交，不可见；2. 版本已提交，但是是在视图创建后提交的，不可见；3. 版本已提交，而且是在视图创建前提交的，可见。</code></pre><h3 id="更新逻辑：当前读"><a href="#更新逻辑：当前读" class="headerlink" title="更新逻辑：当前读"></a>更新逻辑：当前读</h3><p>结论：<strong>更新数据都是先读后写的，而这个读，只能读当前的值，称为“当前读”（current read）。</strong></p><p>对事务B来说，更新的时候，当前读拿到的数据是 (1,2)，更新后生成了新版本的数据 (1,3)，这个新版本的 row trx_id 是 101。在执行事务 B 查询语句的时候，一看自己的版本号是 101，最新数据的版本号也是 101，是自己的更新，可以直接使用，所以查询得到的 k 的值是 3。</p><p>除了 update 语句外，select 语句如果加锁，也是当前读。<br>所以如果把事务 A 的查询语句 <code>select * from t where id=1</code>修改一下，加上 <code>lock in share mode</code> 或 <code>for update</code>，也都可以读到版本号是 101 的数据，返回的 k 的值是 3。下面这两个 select 语句，就是分别加了读锁（S 锁，共享锁）和写锁（X 锁，排他锁）。</p><pre><code>mysql&gt; select k from t where id=1 lock in share mode;mysql&gt; select k from t where id=1 for update;</code></pre><p>Q：事务的可重复读的能力是怎么实现的？<br>可重复读的核心就是一致性读（consistent read）；而事务更新数据的时候，只能用当前读。如果当前的记录的行锁被其他事务占用的话，就需要进入锁等待。</p><h3 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h3><p>InnoDB 的行数据有多个版本，每个数据版本有自己的 row trx_id，每个事务或者语句有自己的一致性视图。普通查询语句是一致性读，一致性读会根据 row trx_id 和一致性视图确定数据版本的可见性。<br>对于可重复读，查询只承认在事务启动前就已经提交完成的数据；<br>对于读提交，查询只承认在语句启动前就已经提交完成的数据；</p><p>参考：<br>丁奇：Mysql实战45讲</p>]]></content>
      
      
      <categories>
          
          <category> MYSQL </category>
          
      </categories>
      
      
        <tags>
            
            <tag> MYSQL </tag>
            
            <tag> MYSQL事务 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Mysql索引</title>
      <link href="/2019/10/06/mysql-suo-yin/"/>
      <url>/2019/10/06/mysql-suo-yin/</url>
      
        <content type="html"><![CDATA[<h2 id="Mysql索引"><a href="#Mysql索引" class="headerlink" title="Mysql索引"></a>Mysql索引</h2><h3 id="索引模型"><a href="#索引模型" class="headerlink" title="索引模型"></a>索引模型</h3><ol><li>哈希表<br> 适用于只有等值查询的场景。不支持最左匹配规则，没办法利用索引完成排序，无法进行范围查询。如果有大量重复键值得情况下，存在哈希碰撞问题</li><li>有序数组<br>有序数组索引只适用于静态存储引擎。查询效率高，但更新数据成本高。</li><li>搜索树<br>二叉树是搜索效率最高的，但是实际上大多数的数据库存储却并不使用二叉树。其原因是，索引不止存在内存中，还要写到磁盘上。<blockquote><p>一棵 100 万节点的平衡二叉树，树高 20。一次查询可能需要访问 20 个数据块。在机械硬盘时代，从磁盘随机读一个数据块需要 10 ms 左右的寻址时间。也就是说，对于一个 100 万行的表，如果使用二叉树来存储，单独访问一个行可能需要 20 个 10 ms 的时间</p></blockquote></li></ol><p>为了让一个查询尽量少地读磁盘，就必须让查询过程访问尽量少的数据块。使用“N 叉”树。这里，“N 叉”树中的“N”取决于数据块的大小。</p><blockquote><p>以 InnoDB 的一个整数字段索引为例，这个 N 差不多是 1200。这棵树高是 4 的时候，就可以存 1200 的 3 次方个值，这已经 17 亿了。考虑到树根的数据块总是在内存中的，一个 10 亿行的表上一个整数字段的索引，查找一个值最多只需要访问 3 次磁盘。其实，树的第二层也有很大概率在内存中，那么访问磁盘的平均次数就更少了。</p></blockquote><h3 id="InnoDB-的索引模型"><a href="#InnoDB-的索引模型" class="headerlink" title="InnoDB 的索引模型"></a>InnoDB 的索引模型</h3><p>在 InnoDB 中，表都是根据主键顺序以索引的形式存放的，这种存储方式的表称为索引组织表。又因为前面我们提到的，InnoDB 使用了 B+ 树索引模型，所以数据都是存储在 B+ 树中的。<br>每一个索引在 InnoDB 里面对应一棵 B+ 树。</p><p>根据叶子节点的内容，索引类型分为主键索引和非主键索引。</p><ul><li>主键索引的叶子节点存的是整行数据，也被称为聚簇索引。</li><li>非主键索引的叶子节点内容是主键的值，非主键索引也被称为二级索引。 </li></ul><p>基于非主键索引的查询需要多扫描一棵索引树。</p><h3 id="索引维护"><a href="#索引维护" class="headerlink" title="索引维护"></a>索引维护</h3><p>B+ 树为了维护索引有序性，在插入新值的时候做必要的维护。如果是递增插入只需要在最大记录后面插入新记录。其它情况，需要逻辑上移动后面数据。如果插入位置所在数据页满了，会申请新数据页挪动部分数据过去，称为<strong>页分裂</strong>，影响性能和数据页的利用率。</p><p>为什么普遍要求建表语句里一定要有自增主键？<code>NOT NULL PRIMARY KEY AUTO_INCREMENT</code></p><ol><li>性能角度<br>自增主键的插入数据模式，符合递增插入的场景。每次插入一条新记录，都是追加操作，都不涉及到挪动其他记录，也不会触发叶子节点的分裂。而有业务逻辑的字段做主键，则往往不容易保证有序插入，这样写数据成本相对较高</li><li>存储空间角度<br>假设你的表中确实有一个唯一字段，比如字符串类型的身份证号。由于每个非主键索引的叶子节点上都是主键的值。如果用身份证号做主键，那么每个二级索引的叶子节点占用约 20 个字节，而如果用整型做主键，则只要 4 个字节，如果是长整型（bigint）则是 8 个字节。</li></ol><p><strong>显然，主键长度越小，普通索引的叶子节点就越小，普通索引占用的空间也就越小。</strong></p><h3 id="覆盖索引"><a href="#覆盖索引" class="headerlink" title="覆盖索引"></a>覆盖索引</h3><p>如果执行的语句是 <code>select ID from T where k between 3 and 5</code>，这时只需要查 ID 的值，而 ID 的值已经在 k 索引树上了，因此可以直接提供查询结果，不需要回表。也就是说，在这个查询里面，索引 k 已经“覆盖了”我们的查询需求，我们称为覆盖索引。</p><h3 id="最左前缀原则"><a href="#最左前缀原则" class="headerlink" title="最左前缀原则"></a>最左前缀原则</h3><p><strong>B+ 树这种索引结构，可以利用索引的“最左前缀”，来定位记录。</strong><br>用（name，age）这个联合索引来分析：SQL 语句的条件是<code>where name like ‘张 %’</code>，也能够用上这个索引。<br>只要满足最左前缀，就可以利用索引来加速检索。这个最左前缀可以是联合索引的最左 N 个字段，也可以是字符串索引的最左 M 个字符。</p><h3 id="索引下推"><a href="#索引下推" class="headerlink" title="索引下推"></a>索引下推</h3><p>以市民表的联合索引（name, age）为例。检索出表中“名字第一个字是张，而且年龄是 10 岁的所有男孩”<br><code>select * from tuser where name like &#39;张 %&#39; and age=10 and ismale=1;</code><br>前缀索引规则，语句在搜索索引树的时候，只能用 “张”，找到第一个满足条件的记录 ID3。之后呢？则比较剩余字段。</p><p>在 MySQL 5.6 之前，只能从 ID3 开始一个个回表。到主键索引上找出数据行，再对比字段值。<br>而 MySQL 5.6 引入的索引下推优化（index condition pushdown)， 可以在索引遍历过程中，对索引中包含的字段先做判断，直接过滤掉不满足条件的记录，减少回表次数。</p><p><img src="https://icecrea-1300414836.cos.ap-beijing.myqcloud.com/mysql/mysql45/04_index/no_index_condition_pushdown.jpg" alt="无索引下推"><br>无索引下推：在 (name,age) 索引里面我特意去掉了 age 的值，这个过程 InnoDB 并不会去看 age 的值，只是按顺序把“name 第一个字是’张’”的记录一条条取出来回表。因此，需要回表 4 次。</p><p><img src="https://icecrea-1300414836.cos.ap-beijing.myqcloud.com/mysql/mysql45/04_index/index_condition_pushdown.jpg" alt="索引下推"><br>索引下推：InnoDB 在 (name,age) 索引内部就判断了 age 是否等于 10，对于不等于 10 的记录，直接判断并跳过。在我们的这个例子中，只需要对 ID4、ID5 这两条记录回表取数据判断，就只需要回表 2 次。</p><hr><p>Q：下列重建索引K与主键索引方式是否正确：</p><pre><code>alter table T drop index k;alter table T add index(k);alter table T drop primary key;alter table T add primary key(id);</code></pre><p>A：重建索引 k 的做法是合理的，可以达到省空间的目的。但是，重建主键的过程不合理。不论是删除主键还是创建主键，都会将整个表重建。所以连着执行这两个语句的话，第一个语句就白做了。这两个语句，你可以用这个语句代替 ： alter table T engine=InnoDB。</p><p>参考：<br>丁奇：Mysql实战45讲<br><a href="https://zhuanlan.zhihu.com/p/78982303" target="_blank" rel="noopener">我以为我对Mysql索引很了解，直到我遇到了阿里的面试官</a></p>]]></content>
      
      
      <categories>
          
          <category> MYSQL </category>
          
      </categories>
      
      
        <tags>
            
            <tag> MYSQL </tag>
            
            <tag> 索引 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Mysql锁</title>
      <link href="/2019/10/03/mysql-suo/"/>
      <url>/2019/10/03/mysql-suo/</url>
      
        <content type="html"><![CDATA[<h2 id="Mysql锁"><a href="#Mysql锁" class="headerlink" title="Mysql锁"></a>Mysql锁</h2><p>MySQL 里面的锁大致可以分成全局锁、表级锁和行锁三类</p><h3 id="全局锁"><a href="#全局锁" class="headerlink" title="全局锁"></a>全局锁</h3><p>顾名思义，全局锁就是对整个数据库实例加锁。MySQL 提供了一个加全局读锁的方法，命令是 <code>Flush tables with read lock (FTWRL)</code>。当你需要让整个库处于只读状态的时候，可以使用这个命令，之后其他线程的以下语句会被阻塞：数据更新语句（数据的增删改）、数据定义语句（包括建表、修改表结构等）和更新类事务的提交语句。</p><p><strong>全局锁的典型使用场景是，做全库逻辑备份。</strong>也就是把整库每个表都 select 出来存成文本。<br>主库上备份，那么在备份期间都不能执行更新。从库上备份，那么备份期间从库不能执行主库同步过来的 binlog，会导致主从延迟。</p><p>备份是否可以不加锁？<br>假设备份期间，有一个用户，他购买了一门课程，业务逻辑里就要扣掉他的余额，然后往已购课程里面加上一门课。<br>假设不加锁。如果时间顺序上是先备份账户余额表，然后用户购买，然后备份用户课程表。在备份结果里用户状态为余额没扣，多了一门课程。后续用该备份恢复数据会有问题。<br><strong>不加锁的话，备份系统备份的得到的库不是一个逻辑时间点，这个视图是逻辑不一致的。</strong></p><p>可重复读隔离级别下可以拿到一致性视图。<br>官方自带的逻辑备份工具是 mysqldump。当 mysqldump 使用参数<code>–single-transaction</code>的时候，导数据之前就会启动一个事务，来确保拿到一致性视图。而由于 MVCC 的支持，这个过程中数据是可以正常更新的。<strong>single-transaction 方法只适用于所有的表使用事务引擎的库。</strong></p><h3 id="表级锁"><a href="#表级锁" class="headerlink" title="表级锁"></a>表级锁</h3><p>MySQL 里面表级别的锁有两种：一种是表锁，一种是元数据锁（meta data lock，MDL)。</p><h4 id="表锁"><a href="#表锁" class="headerlink" title="表锁"></a>表锁</h4><p>表锁的语法是 <code>lock tables … read/write</code>。与 FTWRL 类似，可以用 <code>unlock tables</code> 主动释放锁，也可以在客户端断开的时候自动释放。需要注意，<code>lock tables</code> 语法除了会限制别的线程的读写外，也限定了本线程接下来的操作对象。 </p><p><strong>如果在某个线程 A 中执行 lock tables t1 read, t2 write; 这个语句，则其他线程写 t1、读写 t2 的语句都会被阻塞。同时，线程 A 在执行 unlock tables 之前，也只能执行读 t1、读写 t2 的操作。连写 t1 都不允许，自然也不能访问其他表</strong></p><p>线程A对T加读锁，限制其它线程写T，限制本线程写T，线程A不能访问其它表。<br>线程A对T加写锁，限制其它线程读写T，线程A不能访问其它表。</p><h4 id="MDL锁"><a href="#MDL锁" class="headerlink" title="MDL锁"></a>MDL锁</h4><p>另一类表级的锁是 MDL（metadata lock)。<br>MDL 不需要显式使用，在访问一个表的时候会被自动加上。<br>在 MySQL 5.5 版本中引入了 MDL，<strong>当对一个表做增删改查操作的时候，加 MDL 读锁；当要对表做结构变更操作的时候，加 MDL 写锁。</strong></p><ul><li>读锁之间不互斥，因此你可以有多个线程同时对一张表增删改查。</li><li>读写锁之间、写锁之间是互斥的，用来保证变更表结构操作的安全性。</li></ul><p><strong>踩坑：给一个小表加个字段，导致整个库挂了。</strong><br><img src="https://icecrea-1300414836.cos.ap-beijing.myqcloud.com/mysql/mysql45/06_lock/mdl_crash_database.jpg" alt></p><p>如图：sessionA先启动，加MDL读锁，B也是加MDL读锁，不影响B查询。C需要MDL写锁，因为A的MDL读锁还没有释放，所以C会被阻塞。但是之后在表t上申请MDL读锁的请求也会被C阻塞（增删改查）。等于表现在不可读写了。(问题：C没有加锁成功为什么会阻塞D？应该是因为CD均在同一个锁队列中，决定谁先执行，sessionC在等待的时候就开始阻塞后来的请求了)</p><p>如果表查询语句频繁且客户端有重试，即超时起一个新session请求，库的线程很快会饱满。<br><strong>事务中的MDL锁，在语句执行开始时申请，事务提交后再释放。</strong></p><p><strong>Q：如何安全地给小表加字段？</strong><br>1.首先我们要解决长事务，事务不提交，就会一直占着 MDL 锁。在 MySQL 的 information_schema 库的 innodb_trx 表中，你可以查到当前执行中的事务。如果你要做 DDL 变更的表刚好有长事务在执行，要考虑先暂停 DDL，或者 kill 掉这个长事务。<br>2.如果是一个热点表，请求频繁kill不过来。理想的机制是，在 alter table 语句里面设定等待时间，如果在这个指定的等待时间里面能够拿到 MDL 写锁最好，拿不到也不要阻塞后面的业务语句，先放弃。MariaDB 已经合并了 AliSQL 的这个功能，所以这两个开源分支目前都支持 DDL NOWAIT/WAIT n 这个语法。<br><code>ALTER TABLE tbl_name NOWAIT add column ...</code>  <code>ALTER TABLE tbl_name WAIT N add column ...</code></p><h3 id="行锁"><a href="#行锁" class="headerlink" title="行锁"></a>行锁</h3><p>MySQL 的行锁是在引擎层由各个引擎自己实现的。MyISAM 引擎不支持行锁。</p><p><strong>在 InnoDB 事务中，行锁是在需要的时候才加上的，但并不是不需要了就立刻释放，而是要等到事务结束时才释放。这个就是两阶段锁协议。</strong></p><p><strong>如果你的事务中需要锁多个行，要把最可能造成锁冲突、最可能影响并发度的锁尽量往后放。</strong><br>如影院购票，假设有用户余额扣除票价，影院账户余额增加票价，记录日志操作。在事务中，我们就可以把容易冲突的影院账户余额增加票价安排到最后，这样影院账户余额这一行锁时间就最小，最大程度减少了事务的锁等待，提升并发度。</p><h4 id="死锁和死锁检测"><a href="#死锁和死锁检测" class="headerlink" title="死锁和死锁检测"></a>死锁和死锁检测</h4><p><img src="https://icecrea-1300414836.cos.ap-beijing.myqcloud.com/mysql/mysql45/06_lock/dead_lcok.jpg" alt><br>如图，事务 A 和事务 B 在互相等待对方的资源释放，就是进入了死锁状态。出现死锁后有两种策略：</p><ol><li>直接进入等待，直到超时。这个超时时间可以通过参数 innodb_lock_wait_timeout 来设置。<br>在 InnoDB 中，innodb_lock_wait_timeout 的默认值是 50s。当出现死锁以后，第一个被锁住的线程要过 50s 才会超时退出。设置太小又可能导致误判，简单的锁等待。</li><li>发起死锁检测，发现死锁后，主动回滚死锁链条中的某一个事务，让其他事务得以继续执行。将参数 innodb_deadlock_detect 设置为 on，表示开启这个逻辑。默认开启。<br>每当一个事务被锁的时候，就要看看它所依赖的线程有没有被别人锁住，如此循环，最后判断是否出现了循环等待，也就是死锁。</li></ol><p>每个新来的被堵住的线程，都要判断会不会由于自己的加入导致了死锁，这是一个时间复杂度是 O(n) 的操作。假设有 1000 个并发线程要同时更新同一行，那么死锁检测操作就是 100 万这个量级的。虽然最终检测的结果是没有死锁，但是这期间要消耗大量的 CPU 资源。因此，你就会看到 CPU 利用率很高，但是每秒却执行不了几个事务。</p><p>怎么解决由这种热点行更新导致的性能问题呢？<br>1.控制并发度。如同一行同时最多只有 10 个线程在更新，那么死锁检测的成本很低。并发控制要放在服务端。<br>2.通过将一行改成逻辑上的多行来减少锁冲突。还是以影院账户为例，可以考虑放在多条记录上，比如 10 个记录，影院的账户总额等于这 10 个记录的值的总和。这样每次要给影院账户加金额的时候，随机选其中一条记录来加。这样每次冲突概率变成原来的 1/10，可以减少锁等待个数，也就减少了死锁检测的 CPU 消耗。</p><p><strong>Q：如果你要删除一个表里面的前 10000 行数据，有以下三种方法可以做到，选择哪一种？</strong><br>第一种，直接执行 delete from T limit 10000;<br>第二种，在一个连接中循环执行 20 次 delete from T limit 500;<br>第三种，在 20 个连接中同时执行 delete from T limit 500。</p><p>A：第二种比较合适。第一种方式单个语句占用时间长，锁时间长，且大事务会导致主从延迟。第三种会人为造成锁冲突。</p><p>参考：<br>丁奇：Mysql实战45讲</p>]]></content>
      
      
      <categories>
          
          <category> MYSQL </category>
          
      </categories>
      
      
        <tags>
            
            <tag> MYSQL </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>索引失效实战篇 - 函数操作</title>
      <link href="/2019/10/03/suo-yin-shi-xiao-shi-zhan-pian-han-shu-cao-zuo/"/>
      <url>/2019/10/03/suo-yin-shi-xiao-shi-zhan-pian-han-shu-cao-zuo/</url>
      
        <content type="html"><![CDATA[<h2 id="索引失效实战篇-函数操作"><a href="#索引失效实战篇-函数操作" class="headerlink" title="索引失效实战篇 - 函数操作"></a>索引失效实战篇 - 函数操作</h2><h3 id="1、-条件字段函数操作"><a href="#1、-条件字段函数操作" class="headerlink" title="1、 条件字段函数操作"></a>1、 条件字段函数操作</h3><p><code>mysql&gt; select count(*) from tradelog where month(t_modified)=7;</code></p><p>B+ 树提供的这个快速定位能力，来源于同一层兄弟节点的有序性。<strong>对索引字段做函数操作，可能会破坏索引值的有序性，因此优化器就决定放弃走树搜索功能</strong>。注意：优化器并不是要放弃使用这个索引。对比索引大小选择更小的索引。加了 month() 函数操作，MySQL 无法再使用索引快速定位功能，而只能使用全索引扫描。</p><p>优化器在个问题上确实有“偷懒”行为，即使是对于不改变有序性的函数，也不会考虑使用索引。比如，对于 <code>select * from tradelog where id + 1 = 10000</code></p><h3 id="2、-隐式类型转换"><a href="#2、-隐式类型转换" class="headerlink" title="2、 隐式类型转换"></a>2、 隐式类型转换</h3><p><code>select * from tradelog where tradeid=110717;</code><br>tradeid 的字段类型是 varchar(32)，而输入的参数却是整型，所以需要做类型转换。</p><p>数据类型转换的规则是什么？有一个简单的方法，看 select “10” &gt; 9 的结果</p><pre><code>1. 如果规则是“将字符串转成数字”，那么就是做数字比较，结果应该是 12. 如果规则是“将数字转成字符串”，那么就是做字符串比较，结果应该是 </code></pre><p>验证结果为1，所以在MYSQL中是将<strong>字符串转换成数字</strong><br>对于优化器来说，上面操作等于<code>select * from tradelog where CAST(tradid AS signed int) = 110717;</code>符合上面规则，<strong>对索引字段做函数操作，优化器会放弃走树搜索功能</strong></p><p>注意：<code>select * from tradelog where id=&quot;83126&quot;;</code>该case中，id是int类型，不会导致全表扫描。因为是字符串转整数，所以会先将入参83126转化成数字，在进入索引搜索。</p><h3 id="3、隐式字符编码转换"><a href="#3、隐式字符编码转换" class="headerlink" title="3、隐式字符编码转换"></a>3、隐式字符编码转换</h3><p><code>select d.* from tradelog l, trade_detail d where d.tradeid=l.tradeid and l.id=2;</code><br>链表查询交易记录标和详情表，通过tradeid关联，tradedetail是utf8编码，tradelog是utf8mb4。<br>查询分析结果如下：<br><img src="https://icecrea-1300414836.cos.ap-beijing.myqcloud.com/mysql/mysql45/18_index/explain_result.png" alt></p><pre><code>1. 第一行显示优化器会先在交易记录表 tradelog 上查到 id=2 的行，这个步骤用上了主键索引，rows=1 表示只扫描一行2. 第二行 key=NULL，表示没有用上交易详情表 trade_detail 上的 tradeid 索引，进行了全表扫描</code></pre><p>表 trade_detail 里 tradeid 字段上是有索引的，为什么没有使用？因为这两个表的字符集不同，一个是 utf8，一个是 utf8mb4，所以做表连接查询的时候用不上关联字段的索引。那为什么字符集不同就用不上索引呢？</p><blockquote><p>字符集 utf8mb4 是 utf8 的超集，所以当这两个类型的字符串在做比较的时候，MySQL 内部的操作是，先把 utf8 字符串转成 utf8mb4 字符集，再做比较。可以理解为=“按数据长度增加的方向”进行转换。</p></blockquote><p>实际上等同如下写法：<br><code>select * from trade_detail where CONVERT(traideid USING utf8mb4)=$L2.tradeid.value</code></p><p><strong>连接过程中要求在被驱动表的索引字段上加函数操作</strong>，是直接导致对被驱动表做全表扫描的原因。</p><p>对比验证<code>select l.operator from tradelog l , trade_detail d where d.tradeid=l.tradeid and d.id=4;</code><br>此时转换成<code>select operator from tradelog where traideid =CONVERT($R4.tradeid.value USING utf8mb4);</code>CONVERT 函数是加在输入参数上的，这样就可以用上被驱动表的 traideid 索引。</p><p>第一种查询的解决方案：</p><ol><li>转换成utf8mb4</li><li>修改SQL语句 <code>select d.* from tradelog l , trade_detail d where d.tradeid=CONVERT(l.tradeid USING utf8) and l.id=2;</code></li></ol><h3 id="总结："><a href="#总结：" class="headerlink" title="总结："></a>总结：</h3><p><strong>对索引字段做函数操作，可能会破坏索引值的有序性，因此优化器就决定放弃走树搜索功能。</strong></p><p>参考：<br>丁奇：MYSQL实战45讲</p>]]></content>
      
      
      <categories>
          
          <category> MYSQL </category>
          
      </categories>
      
      
        <tags>
            
            <tag> MYSQL </tag>
            
            <tag> 索引 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>JVM问题排查指令总结</title>
      <link href="/2019/09/29/jvm-wen-ti-pai-cha-zhi-ling-zong-jie/"/>
      <url>/2019/09/29/jvm-wen-ti-pai-cha-zhi-ling-zong-jie/</url>
      
        <content type="html"><![CDATA[<h2 id="JVM问题排查指令总结"><a href="#JVM问题排查指令总结" class="headerlink" title="JVM问题排查指令总结"></a>JVM问题排查指令总结</h2><h4 id="常用分析指令"><a href="#常用分析指令" class="headerlink" title="常用分析指令"></a>常用分析指令</h4><ol><li><p>查看各个类的实例大小与个数<br><code>sudo -u tomcat jmap -histo pid</code></p></li><li><p>DUMP内存，获取对应的内存快照<br><code>sudo -u tomcat jmap -dump:format=b,file=dumpxx.bin pid</code> </p></li><li><p>CPU飙高排查线程信息<br><code>top -Hp pid</code> 查看Java进程信息 p : 根据CPU使用百分比大小进行排序<br><code>printf &quot;%x\n&quot; 21742</code> 将CPU高的线程ID转换成十六进制<br><code>sudo -u tomcat jstack -l 21711 | grep 54ee</code> 查看线程栈中对应CPU高的线程信息</p></li><li><p>统计进程状态个数<br><code>sudo -utomcat jstack 5020 |grep &#39;java.lang.Thread.State&#39; | awk &#39;{print $2,$3,$4,$5}&#39; | sort | uniq -c</code></p><pre><code>36 RUNNABLE3 TIMED_WAITING (on object monitor)13 TIMED_WAITING (parking)6 TIMED_WAITING (sleeping)3 WAITING (on object monitor)47 WAITING (parking)</code></pre></li></ol><hr><h4 id="MAT-使用简介"><a href="#MAT-使用简介" class="headerlink" title="MAT 使用简介"></a>MAT 使用简介</h4><p>Shallow Heap ：一个对象内存的消耗大小，不包含对其他对象的引用；<br>Retained Heap ：是shallow Heap的总和，也就是该对象被GC之后所能回收的内存大小<br>在某一项上右键打开菜单选择 list objects ：<br>with incoming references 将列出哪些类引入该类；<br>with outgoing references 列出该类引用了哪些类</p>]]></content>
      
      
      <categories>
          
          <category> JVM </category>
          
      </categories>
      
      
        <tags>
            
            <tag> JVM </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>CLOSE-WAIT的排查之旅</title>
      <link href="/2019/09/29/close-wait-de-pai-cha-zhi-lu/"/>
      <url>/2019/09/29/close-wait-de-pai-cha-zhi-lu/</url>
      
        <content type="html"><![CDATA[<h2 id="CLOSE-WAIT的排查之旅"><a href="#CLOSE-WAIT的排查之旅" class="headerlink" title="CLOSE-WAIT的排查之旅"></a>CLOSE-WAIT的排查之旅</h2><h4 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h4><p>通过监控中发现，线上机器TCP连接中，CLOSE-WAIT状态的量较高。对该问题进行排查</p><h4 id="TCP基础介绍"><a href="#TCP基础介绍" class="headerlink" title="TCP基础介绍"></a>TCP基础介绍</h4><p>首先介绍下TCP连接的状态，四次挥手关闭连接的状态变化如下图所示。<br>从图中可以看到，<strong>主动关闭</strong>的一方会发出FIN包，被动关闭的一方响应ACK包，此时被动关闭的一方进入CLOSE-WAIT状态。如果一切正常，被动关闭的一方也会发出FIN包，进入LAST-ACK状态。<br><img src="https://icecrea-1300414836.cos.ap-beijing.myqcloud.com/network/tcp_close_geek.jpg" alt></p><p>通常情况下，服务器中CLOSE-WAIT状态停留时间很短，<strong>如果发现大量CLOSE-WAIT状态，说明被动关闭的一方没有及时发出FIN包</strong></p><p>可能导致问题的原因：</p><ul><li>程序未正确释放资源</li><li>客户端超时，主动关闭连接，同时服务器却没有正确释放连接</li></ul><blockquote><p>举例一个场景：<br>服务器A会去请求服务器B上面的apache获取文件资源，正常情况下，如果请求成功，那么在抓取完资源后服务器A会主动发出关闭连接的请求，这个时候就是主动关闭连接，连接状态我们可以看到是TIME_WAIT。如果一旦发生异常呢？假设请求的资源服务器B上并不存在，那么这个时候就会由服务器B发出关闭连接的请求，服务器A就是被动的关闭了连接，如果服务器A被动关闭连接之后自己并没有释放连接，那就会造成CLOSE_WAIT的状态了。</p></blockquote><p>而对于JAVA项目来说，则需要重点观察HTTP相关调用与连接的释放。</p><h4 id="代码层面白盒分析"><a href="#代码层面白盒分析" class="headerlink" title="代码层面白盒分析"></a>代码层面白盒分析</h4><p>一开始是从代码层面进行分析，我们使用了Http-Client连接池，<br>对于3.1的版本，我们使用了<code>MultiThreadedHttpConnectionManager</code>作为多线程管理器，并且在<code>finally</code>块中，调用了<code>HttpMethod#releaseConnection</code>方法，对连接进行释放，并没有发现问题。</p><p>而因为使用了连接池复用的缘故，同样不建议采用手动关闭连接的形式。如</p><ol><li>通过设置header由服务端自动关闭。<code>method.setHeader(&quot;Connection&quot;, &quot;close&quot;)</code><br>HTTP1.1中默认启用Keep-Alive，这是HTTP一种连接复用机制，加入”Connection: close”会关闭长连接，无法在一个TCP连接进行多次HTTP会话，降低性能。</li><li>在<code>method.releaseConnection()</code> 之后 通过获取HttpConnectionManager，进行关闭<code>hc.getConnectionManager().shutdown();</code>  直接关闭连接池，同样对性能影响较大不可取。</li></ol><h4 id="抓包分析定位请求"><a href="#抓包分析定位请求" class="headerlink" title="抓包分析定位请求"></a>抓包分析定位请求</h4><p>在代码中我们发现使用了HttpClient进行网络请求，但是用法与调用比较混乱，3.x，4.x，以及公司封装版本均有使用，仅仅白盒分析难以发现问题。所以通过tcpdump对线上机器进行抓包分析。</p><ol><li>dump所有tcp报文到文件<br><code>sudo tcpdump  -nn -w flightorder.pcap -v</code></li><li>查看监控，在closewait的上升期，查询最新的连接信息<br><code>sudo netstat -anp |grep CL</code></li><li>通过最新的close-wait 端口 查看tcp的信息<br><code>tcpdump -r flightorder.pcap |grep &#39;35493&#39;</code></li></ol><p>通过报文中的http请求，锁定应用级别相关api</p><h4 id="一行代码的低级错误"><a href="#一行代码的低级错误" class="headerlink" title="一行代码的低级错误"></a>一行代码的低级错误</h4><p>定位代码发现，在该处调用中，封装了post相关请求，但是在该方法中，每次调用均重新生成了新的HttpClient，而不是公共静态的httpclient。意味着每一次请求均会生成一个新的连接池进行处理。将实例化代码抽出后发布，发现CLOSE-WAIT量消失，问题解决。</p><h4 id="Http的Keep-alive机制"><a href="#Http的Keep-alive机制" class="headerlink" title="Http的Keep-alive机制"></a>Http的Keep-alive机制</h4><p>定位解决了问题，但是还有一些疑问，<strong>主动方是如何触发的关闭呢？</strong></p><p>这里就需要先普及下Http keepalive机制。Http的Keep alive是一种TCP连接复用机制，在同一个TCP连接上传送多个HTTP，提高Socket的效率。而TCP的keep-alive是TCP的一种检测TCP连接状况的保鲜机制，注意两者区分。</p><p>Http1.1之前（未显示指定Connection:keep-alive）每个http请求都要求打开一个tcp socket连接，并且使用一次之后就断开这个tcp连接。对于如今这种一个页面少则几个多则几十几百个的请求的现状来说这显然不是一种高效的使用方式，http1.1之后默认开启keep-alive，通过使用keep-alive机制，可以减少tcp连接建立次数，以此提高性能和提高http服务器的吞吐率(更少的tcp连接意味着更少的系统内核调用,socket的accept()和close()调用。</p><p>然而keep-alive如果配置不当同样存在风险，长时间的tcp连接容易导致系统资源无效占用。正确地设置keep-alive timeout时间非常重要。那么是否是因为keep-alive超时，发起的主动关闭连接呢？结合tcpdump结果分析</p><p><img src="https://icecrea-1300414836.cos.ap-beijing.myqcloud.com/network/closewait_wireshark.png" alt></p><p>此处我使用wireshark，对上面的抓包结果分析，从图中圈红部分我们可以发现，最后一次ACK和发起主动关闭间隔30s，多个case结果均相同。那么对应的远程主机，也就是ng的keep-alive timeout应该是30，跟运维确认ng配置，得到验证<code>keepalive_timeout  30;  client_body_timeout 30s; client_header_timeout 30s;</code></p><h4 id="TCP连接与Finalize机制"><a href="#TCP连接与Finalize机制" class="headerlink" title="TCP连接与Finalize机制"></a>TCP连接与Finalize机制</h4><p>在观察监控时，还发现一个奇怪的现象，每过5分钟，CLOSE-WAIT的量变断崖式下降。第一反应是否是系统GC掉了？观察GC日志，发现时间点吻合。CLOSE_WAIT变更为LAST_ACK的tcp连接，同时都伴随着gc的发生。</p><p>为什么gc会导致tcp连接的关闭呢？这是就不得不提java的finalize机制。</p><blockquote><p>finalize()方法的工作原理：<br>触发gc时，一旦垃圾回收器准备好释放对象占用的存储空间，如果该对象未重写finalize()方法则可以直接回收，否则会去调用finalize()方法进行一些必要的清理工作。只有到下一次再进行垃圾回收动作的时候，才会真正释放这个对象所占用的内存空间。</p></blockquote><blockquote><p>假定你的对象（并非使用new方法）获得了一块“特殊”的内存区域，由于垃圾回收器只知道那些显示地经由new分配的内存空间，所以它不知道该如何释放这块“特殊”的内存区域，那么这个时候java允许在类中定义一个由finalize()方法，通过这个方法安全的回收“特殊”区域，特殊区域如文件(如java.util.zip.ZipFile)、流(如org.apache.commons.io.input.AutoCloseInputStream)、管道(如java.net.AbstractPlainSocketImpl)等。</p></blockquote><p>apache的httpclient的使用的就是<code>java.net.AbstractPlainSocketImpl</code>(调用的是<code>java.net.SocksSocketImpl，AbstractPlainSocketImpl</code>的子类)中的关闭方法</p><pre><code>protected void finalize() throws IOException {    close();}protected void close() throws IOException {    if (cmdsock != null)        cmdsock.close();    cmdsock = null;    super.close();}</code></pre>]]></content>
      
      
      <categories>
          
          <category> 计算机网络 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 计算机网络 </tag>
            
            <tag> TCP </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Hexo+Github搭建博客指南</title>
      <link href="/2019/09/27/da-jian-bo-ke/"/>
      <url>/2019/09/27/da-jian-bo-ke/</url>
      
        <content type="html"><![CDATA[<h2 id="安装Nodejs"><a href="#安装Nodejs" class="headerlink" title="安装Nodejs"></a>安装Nodejs</h2><p>安装Nodejs 稳定版：<br><a href="https://link.zhihu.com/?target=https%3A//nodejs.org/dist/v9.11.1/node-v9.11.1-x64.msi" target="_blank" rel="noopener">https://link.zhihu.com/?target=https%3A//nodejs.org/dist/v9.11.1/node-v9.11.1-x64.msi</a></p><h2 id="安装Hexo"><a href="#安装Hexo" class="headerlink" title="安装Hexo"></a>安装Hexo</h2><p>进入博客目录(如e:/blog) 右键git bash<br>npm i hexo-cli -g安装Hexo<br>hexo -v验证是否安装成功。<br>hexo init初始化文件夹<br>npm install安装必备的组件。<br>hexo g生成静态网页，每次改动要生成一下<br>hexo s打开本地服务器预览，浏览器打开<a href="http://localhost:4000/" target="_blank" rel="noopener">http://localhost:4000/</a></p><p>修改博客根目录下的_config.yml文件，repositrory改成github上对应项目地址</p><pre><code>deploy:  type: git  repository: git@github.com:icecrea/icecrea.github.io.git  branch: master</code></pre><h2 id="写文章，发布文章"><a href="#写文章，发布文章" class="headerlink" title="写文章，发布文章"></a>写文章，发布文章</h2><p>进入博客目录(如e:/blog) 右键git bash<br>安装扩展npm i hexo-deployer-git<br>输入hexo new post “article title”，新建文章<br>hexo d上传到github上</p><h2 id="指定git账户名"><a href="#指定git账户名" class="headerlink" title="指定git账户名"></a>指定git账户名</h2><p>在_config.yml中设置</p><pre><code># You can use this:deploy:  type: git  repo: &lt;repository url&gt;  branch: [branch]  message: [message]  name: [git user]  email: [git email]  extend_dirs: [extend directory]</code></pre><p>注意： 如果.deploy_git目录已经生成的情况下，需要删掉整个目录，再执行一次hexo d才行</p><h2 id="主题更换"><a href="#主题更换" class="headerlink" title="主题更换"></a>主题更换</h2><p>项目推荐 ：<a href="https://github.com/blinkfox/hexo-theme-matery/blob/develop/README_CN.md" target="_blank" rel="noopener">https://github.com/blinkfox/hexo-theme-matery/blob/develop/README_CN.md</a></p><p>参考： <a href="https://zhuanlan.zhihu.com/p/35668237" target="_blank" rel="noopener">https://zhuanlan.zhihu.com/p/35668237</a></p>]]></content>
      
      
      <categories>
          
          <category> 博客 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 博客 </tag>
            
        </tags>
      
    </entry>
    
    
  
  
</search>
